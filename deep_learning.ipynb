{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 08:43:03.299895: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-11-22 08:43:03.299927: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.0\n",
      "Keras version: 2.4.0\n",
      "GPU is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 08:43:04.286623: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-11-22 08:43:04.286768: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-11-22 08:43:04.286782: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-11-22 08:43:04.286803: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-c8a454): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from midi2audio import FluidSynth\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_wav(midi_file, wav_file, soundfont_path):\n",
    "    fs = FluidSynth(soundfont_path)  # Load the soundfont\n",
    "    fs.midi_to_audio(midi_file, wav_file)  # Convert MIDI to WAV\n",
    "    print(f\"Converted {midi_file} to {wav_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_0.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_07_R1_2004_01_ORIG_MID--AUDIO_07_R1_2004_04_Track04_wav.midi to maestro_dataset/mp3/sound_file_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_1.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_03_Track03_wav.midi to maestro_dataset/mp3/sound_file_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_2.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_17_R1_2004_01-02_ORIG_MID--AUDIO_20_R2_2004_04_Track04_wav.midi to maestro_dataset/mp3/sound_file_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_3.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_01_R1_2004_04-05_ORIG_MID--AUDIO_01_R1_2004_06_Track06_wav.midi to maestro_dataset/mp3/sound_file_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_4.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_09_R1_2004_05_ORIG_MID--AUDIO_09_R1_2004_07_Track07_wav.midi to maestro_dataset/mp3/sound_file_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_5.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_01_R1_2004_03_ORIG_MID--AUDIO_01_R1_2004_04_Track04_wav.midi to maestro_dataset/mp3/sound_file_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_6.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_17_R1_2004_04_ORIG_MID--AUDIO_17_R1_2004_11_Track11_wav.midi to maestro_dataset/mp3/sound_file_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_7.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_22_R2_2004_01_ORIG_MID--AUDIO_22_R2_2004_02_Track02_wav.midi to maestro_dataset/mp3/sound_file_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_8.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_07_R1_2004_01_ORIG_MID--AUDIO_07_R1_2004_12_Track12_wav.midi to maestro_dataset/mp3/sound_file_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_9.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_08_Track08_wav.midi to maestro_dataset/mp3/sound_file_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_10.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_17_R2_2004_01_ORIG_MID--AUDIO_17_R2_2004_01_Track01_wav.midi to maestro_dataset/mp3/sound_file_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_11.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_10_R1_2004_01-02_ORIG_MID--AUDIO_10_R1_2004_02_Track02_wav.midi to maestro_dataset/mp3/sound_file_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_12.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_19_R1_2004_01-02_ORIG_MID--AUDIO_19_R1_2004_02_Track02_wav.midi to maestro_dataset/mp3/sound_file_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_13.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_17_R1_2004_04_ORIG_MID--AUDIO_17_R1_2004_09_Track09_wav.midi to maestro_dataset/mp3/sound_file_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_14.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_15_R2_2004_01_ORIG_MID--AUDIO_15_R2_2004_04_Track04_wav.midi to maestro_dataset/mp3/sound_file_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_15.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_19_R1_2004_01-02_ORIG_MID--AUDIO_19_R1_2004_03_Track03_wav.midi to maestro_dataset/mp3/sound_file_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_16.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_06_Track06_wav.midi to maestro_dataset/mp3/sound_file_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_17.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_02_Track02_wav--2.midi to maestro_dataset/mp3/sound_file_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_18.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_01_R1_2004_04-05_ORIG_MID--AUDIO_01_R1_2004_05_Track05_wav.midi to maestro_dataset/mp3/sound_file_18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_19.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_04_R1_2004_01-02_ORIG_MID--AUDIO_04_R1_2004_01_Track01_wav.midi to maestro_dataset/mp3/sound_file_19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_20.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_11_R1_2004_03-04_ORIG_MID--AUDIO_11_R1_2004_03_Track03_wav.midi to maestro_dataset/mp3/sound_file_20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_21.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_22_R1_2004_01-04_ORIG_MID--AUDIO_22_R1_2004_17_Track17_wav.midi to maestro_dataset/mp3/sound_file_21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_22.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_16_R1_2004_01-08_ORIG_MID--AUDIO_16_R1_2004_08_Track08_wav.midi to maestro_dataset/mp3/sound_file_22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_23.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_21_R1_2004_01_ORIG_MID--AUDIO_21_R1_2004_01_Track01_wav.midi to maestro_dataset/mp3/sound_file_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_24.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_18_R1_2004_01-02_ORIG_MID--AUDIO_18_R1_2004_05_Track05_wav.midi to maestro_dataset/mp3/sound_file_24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_25.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_12_01_2004_01-05_ORIG_MID--AUDIO_12_R1_2004_07_Track07_wav.midi to maestro_dataset/mp3/sound_file_25.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_26.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_10_R1_2004_05_ORIG_MID--AUDIO_10_R1_2004_05_Track05_wav.midi to maestro_dataset/mp3/sound_file_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_27.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_13_01_2004_01-05_ORIG_MID--AUDIO_13_R1_2004_02_Track02_wav.midi to maestro_dataset/mp3/sound_file_27.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_28.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_12_01_2004_01-05_ORIG_MID--AUDIO_12_R1_2004_03_Track03_wav--1.midi to maestro_dataset/mp3/sound_file_28.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_29.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_16_R2_2004_01_ORIG_MID--AUDIO_16_R2_2004_03_Track03_wav.midi to maestro_dataset/mp3/sound_file_29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_30.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_17_R1_2004_01-03_ORIG_MID--AUDIO_17_R1_2004_03_Track03_wav.midi to maestro_dataset/mp3/sound_file_30.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_31.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_SMF_22_R1_2004_01-04_ORIG_MID--AUDIO_22_R1_2004_03_Track03_wav.midi to maestro_dataset/mp3/sound_file_31.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'maestro_dataset/mp3/sound_file_32.wav'..\n",
      "Converted maestro_dataset/midi/MIDI-Unprocessed_XP_08_R1_2004_04-06_ORIG_MID--AUDIO_08_R1_2004_05_Track05_wav--1.midi to maestro_dataset/mp3/sound_file_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17077/1574302963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmidi_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwav_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"sound_file_{sound_file_counter}.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmidi_to_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoundfont_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msound_file_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17077/74502128.py\u001b[0m in \u001b[0;36mmidi_to_wav\u001b[0;34m(midi_file, wav_file, soundfont_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmidi_to_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoundfont_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFluidSynth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoundfont_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the soundfont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi_to_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert MIDI to WAV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Converted {midi_file} to {wav_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/site-packages/midi2audio.py\u001b[0m in \u001b[0;36mmidi_to_audio\u001b[0;34m(self, midi_file, audio_file)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmidi_to_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fluidsynth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-ni'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msound_font\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sound_file_counter = 0\n",
    "soundfont_path = \"FluidR3_GM.sf2\"\n",
    "wav_path = \"maestro_dataset/mp3/\"\n",
    "\n",
    "for path, _ , file_names in os.walk('maestro_dataset/midi'):\n",
    "    for file_name in file_names:\n",
    "        midi_file = os.path.join(path, file_name)\n",
    "        wav_file = os.path.join(wav_path, f\"sound_file_{sound_file_counter}.wav\")\n",
    "        midi_to_wav(midi_file, wav_file, soundfont_path)\n",
    "\n",
    "        sound_file_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    \"\"\"Loader is responsible for loading an audio file.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, duration, mono):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.mono = mono\n",
    "\n",
    "    def load(self, file_path):\n",
    "        signal = librosa.load(file_path,\n",
    "                              sr=self.sample_rate,\n",
    "                              duration=self.duration,\n",
    "                              mono=self.mono)[0]\n",
    "        return signal\n",
    "\n",
    "class Padder:\n",
    "    \"\"\"Padder is responsible to apply padding to an array.\"\"\"\n",
    "\n",
    "    def __init__(self, mode=\"constant\"):\n",
    "        self.mode = mode\n",
    "\n",
    "    def left_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (num_missing_items, 0),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "    def right_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (0, num_missing_items),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "\n",
    "class LogSpectrogramExtractor:\n",
    "    \"\"\"LogSpectrogramExtractor extracts log spectrograms (in dB) from a\n",
    "    time-series signal.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frame_size, hop_length):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def extract(self, signal):\n",
    "        stft = librosa.stft(signal,\n",
    "                            n_fft=self.frame_size,\n",
    "                            hop_length=self.hop_length)[:-1]\n",
    "        spectrogram = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "        return log_spectrogram\n",
    "\n",
    "\n",
    "class MinMaxNormaliser:\n",
    "    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n",
    "\n",
    "    def __init__(self, min_val, max_val):\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "\n",
    "    def normalise(self, array):\n",
    "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
    "        norm_array = norm_array * (self.max - self.min) + self.min\n",
    "        return norm_array\n",
    "\n",
    "    def denormalise(self, norm_array, original_min, original_max):\n",
    "        array = (norm_array - self.min) / (self.max - self.min)\n",
    "        array = array * (original_max - original_min) + original_min\n",
    "        return array\n",
    "\n",
    "\n",
    "class Saver:\n",
    "    \"\"\"saver is responsible to save features, and the min max values.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
    "        self.feature_save_dir = feature_save_dir\n",
    "        self.min_max_values_save_dir = min_max_values_save_dir\n",
    "\n",
    "    def save_feature(self, feature, file_path):\n",
    "        save_path = self._generate_save_path(file_path)\n",
    "        np.save(save_path, feature)\n",
    "\n",
    "    def save_min_max_values(self, min_max_values):\n",
    "        save_path = os.path.join(self.min_max_values_save_dir,\n",
    "                                 \"min_max_values.pkl\")\n",
    "        self._save(min_max_values, save_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _save(data, save_path):\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def _generate_save_path(self, file_path):\n",
    "        file_name = os.path.split(file_path)[1]\n",
    "        save_path = os.path.join(self.feature_save_dir, file_name + \".npy\")\n",
    "        return save_path\n",
    "\n",
    "\n",
    "class PreprocessingPipeline:\n",
    "    \"\"\"PreprocessingPipeline processes audio files in a directory, applying\n",
    "    the following steps to each file:\n",
    "        1- load a file\n",
    "        2- pad the signal (if necessary)\n",
    "        3- extracting log spectrogram from signal\n",
    "        4- normalise spectrogram\n",
    "        5- save the normalised spectrogram\n",
    "\n",
    "    Storing the min max values for all the log spectrograms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.padder = None\n",
    "        self.extractor = None\n",
    "        self.normaliser = None\n",
    "        self.saver = None\n",
    "        self.min_max_values = {}\n",
    "        self._loader = None\n",
    "        self._num_expected_samples = None\n",
    "\n",
    "    @property\n",
    "    def loader(self):\n",
    "        return self._loader\n",
    "\n",
    "    @loader.setter\n",
    "    def loader(self, loader):\n",
    "        self._loader = loader\n",
    "        self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
    "\n",
    "    def process(self, audio_files_dir):\n",
    "        for root, _, files in os.walk(audio_files_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                self._process_file(file_path)\n",
    "                print(f\"Processed file {file_path}\")\n",
    "        self.saver.save_min_max_values(self.min_max_values)\n",
    "\n",
    "    def _process_file(self, file_path):\n",
    "        signal = self.loader.load(file_path)\n",
    "        if self._is_padding_necessary(signal):\n",
    "            signal = self._apply_padding(signal)\n",
    "        feature = self.extractor.extract(signal)\n",
    "        norm_feature = self.normaliser.normalise(feature)\n",
    "        save_path = self.saver.save_feature(norm_feature, file_path)\n",
    "        self._store_min_max_value(save_path, feature.min(), feature.max())\n",
    "\n",
    "    def _is_padding_necessary(self, signal):\n",
    "        if len(signal) < self._num_expected_samples:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _apply_padding(self, signal):\n",
    "        num_missing_samples = self._num_expected_samples - len(signal)\n",
    "        padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
    "        return padded_signal\n",
    "\n",
    "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
    "        self.min_max_values[save_path] = {\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file maestro_dataset/mp3/sound_file_21.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_14.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_27.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_15.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_17.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_8.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_6.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_19.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_20.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_13.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_23.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_3.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_33.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_12.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_5.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_0.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_10.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_31.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_16.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_9.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_18.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_22.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_11.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_1.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_2.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_24.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_28.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_25.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_7.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_4.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_30.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_26.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_29.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_32.wav\n"
     ]
    }
   ],
   "source": [
    "# FRAME_SIZE = 512\n",
    "# HOP_LENGTH = 256\n",
    "# DURATION = 30.0  # in seconds\n",
    "# SAMPLE_RATE = 22050\n",
    "# MONO = True\n",
    "\n",
    "# SPECTROGRAMS_SAVE_DIR = \"maestro_dataset/spectograms\"\n",
    "# MIN_MAX_VALUES_SAVE_DIR = \"maestro_dataset/minmax\"\n",
    "# FILES_DIR = \"maestro_dataset/mp3\"\n",
    "\n",
    "# # instantiate all objects\n",
    "# loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "# padder = Padder()\n",
    "# log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "# min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "# saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
    "\n",
    "# preprocessing_pipeline = PreprocessingPipeline()\n",
    "# preprocessing_pipeline.loader = loader\n",
    "# preprocessing_pipeline.padder = padder\n",
    "# preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
    "# preprocessing_pipeline.normaliser = min_max_normaliser\n",
    "# preprocessing_pipeline.saver = saver\n",
    "\n",
    "# preprocessing_pipeline.process(FILES_DIR)\n",
    "\n",
    "FRAME_SIZE = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 0.74  # in seconds\n",
    "SAMPLE_RATE = 22050\n",
    "MONO = True\n",
    "\n",
    "SPECTROGRAMS_SAVE_DIR = \"maestro_dataset/spectograms\"\n",
    "MIN_MAX_VALUES_SAVE_DIR = \"maestro_dataset/minmax\"\n",
    "FILES_DIR = \"maestro_dataset/mp3\"\n",
    "\n",
    "# instantiate all objects\n",
    "loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "padder = Padder()\n",
    "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
    "\n",
    "preprocessing_pipeline = PreprocessingPipeline()\n",
    "preprocessing_pipeline.loader = loader\n",
    "preprocessing_pipeline.padder = padder\n",
    "preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
    "preprocessing_pipeline.normaliser = min_max_normaliser\n",
    "preprocessing_pipeline.saver = saver\n",
    "\n",
    "preprocessing_pipeline.process(FILES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_reconstruction_loss(y_target, y_predicted):\n",
    "    error = y_target - y_predicted\n",
    "    reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def calculate_kl_loss(model):\n",
    "    # wrap `_calculate_kl_loss` such that it takes the model as an argument,\n",
    "    # returns a function which can take arbitrary number of arguments\n",
    "    # (for compatibility with `metrics` and utility in the loss function)\n",
    "    # and returns the kl loss\n",
    "    def _calculate_kl_loss(*args):\n",
    "        kl_loss = -0.5 * K.sum(1 + model.log_variance - K.square(model.mu) -\n",
    "                               K.exp(model.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "    return _calculate_kl_loss\n",
    "\n",
    "\n",
    "class VAE:\n",
    "    \"\"\"\n",
    "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
    "    with mirrored encoder and decoder components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 conv_filters,\n",
    "                 conv_kernels,\n",
    "                 conv_strides,\n",
    "                 latent_space_dim):\n",
    "        self.input_shape = input_shape # [28, 28, 1]\n",
    "        self.conv_filters = conv_filters # [2, 4, 8]\n",
    "        self.conv_kernels = conv_kernels # [3, 5, 3]\n",
    "        self.conv_strides = conv_strides # [1, 2, 2]\n",
    "        self.latent_space_dim = latent_space_dim # 2\n",
    "        self.reconstruction_loss_weight = 1000\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=self._calculate_combined_loss,\n",
    "                           metrics=[_calculate_reconstruction_loss,\n",
    "                                    calculate_kl_loss(self)])\n",
    "\n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        self.model.fit(x_train,\n",
    "                       x_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       shuffle=True)\n",
    "\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = VAE(*parameters)\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
    "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
    "                                                         + kl_loss\n",
    "        return combined_loss\n",
    "\n",
    "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
    "        error = y_target - y_predicted\n",
    "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "        return reconstruction_loss\n",
    "\n",
    "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
    "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
    "                               K.exp(self.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(parameters, f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.model.save_weights(save_path)\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "\n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "\n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "\n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        \"\"\"Add conv transpose blocks.\"\"\"\n",
    "        # loop through all the conv layers in reverse order and stop at the\n",
    "        # first layer\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=self.conv_kernels[0],\n",
    "            strides=self.conv_strides[0],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
    "        return output_layer\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "\n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
    "        x = encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
    "        conv 2d + ReLU + batch normalization.\n",
    "        \"\"\"\n",
    "        layer_number = layer_index + 1\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_bottleneck(self, x):\n",
    "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
    "        layer).\n",
    "        \"\"\"\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
    "        self.log_variance = Dense(self.latent_space_dim,\n",
    "                                  name=\"log_variance\")(x)\n",
    "\n",
    "        def sample_point_from_normal_distribution(args):\n",
    "            mu, log_variance = args\n",
    "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
    "                                      stddev=1.)\n",
    "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
    "            return sampled_point\n",
    "\n",
    "        print(self.input_shape)\n",
    "\n",
    "        x = Lambda(sample_point_from_normal_distribution,\n",
    "               name=\"encoder_output\")([self.mu, self.log_variance])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 150\n",
    "\n",
    "SPECTROGRAMS_PATH = \"maestro_dataset/spectograms\"\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 64, 1)\n",
    "    print(x_train.shape)\n",
    "    print(x_train)\n",
    "    return x_train\n",
    "\n",
    "\n",
    "def train(x_train, learning_rate, batch_size, epochs):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(256, 64, 1),\n",
    "        conv_filters=(512, 256, 128, 64, 32),\n",
    "        conv_kernels=(3, 3, 3, 3, 3),\n",
    "        conv_strides=(2, 2, 2, 2, (2, 1)),\n",
    "        latent_space_dim=128\n",
    "    )\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, epochs)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 256, 64, 1)\n",
      "[[[[0.814349  ]\n",
      "   [0.9856756 ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   [0.9978009 ]]\n",
      "\n",
      "  [[0.7738697 ]\n",
      "   [0.8994985 ]\n",
      "   [0.8959378 ]\n",
      "   ...\n",
      "   [0.8959378 ]\n",
      "   [0.8959378 ]\n",
      "   [0.89942753]]\n",
      "\n",
      "  [[0.65179914]\n",
      "   [0.588238  ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.3570581 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.814349  ]\n",
      "   [0.9856756 ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   [0.9978009 ]]\n",
      "\n",
      "  [[0.7738697 ]\n",
      "   [0.8994985 ]\n",
      "   [0.8959378 ]\n",
      "   ...\n",
      "   [0.8959378 ]\n",
      "   [0.8959378 ]\n",
      "   [0.89942753]]\n",
      "\n",
      "  [[0.65179914]\n",
      "   [0.588238  ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.3570581 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.814349  ]\n",
      "   [0.9856756 ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   [0.9978009 ]]\n",
      "\n",
      "  [[0.7738697 ]\n",
      "   [0.8994985 ]\n",
      "   [0.8959378 ]\n",
      "   ...\n",
      "   [0.8959378 ]\n",
      "   [0.8959378 ]\n",
      "   [0.89942753]]\n",
      "\n",
      "  [[0.65179914]\n",
      "   [0.588238  ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.3570581 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.814349  ]\n",
      "   [0.9856756 ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   [0.9978009 ]]\n",
      "\n",
      "  [[0.7738697 ]\n",
      "   [0.8994985 ]\n",
      "   [0.8959378 ]\n",
      "   ...\n",
      "   [0.8959378 ]\n",
      "   [0.8959378 ]\n",
      "   [0.89942753]]\n",
      "\n",
      "  [[0.65179914]\n",
      "   [0.588238  ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.3570581 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.36069632]\n",
      "   [0.48459926]\n",
      "   [0.49495864]\n",
      "   ...\n",
      "   [0.761258  ]\n",
      "   [0.7528709 ]\n",
      "   [0.8101406 ]]\n",
      "\n",
      "  [[0.33142176]\n",
      "   [0.4222762 ]\n",
      "   [0.4197011 ]\n",
      "   ...\n",
      "   [0.8754574 ]\n",
      "   [0.8417719 ]\n",
      "   [0.89133054]]\n",
      "\n",
      "  [[0.24314065]\n",
      "   [0.1971734 ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.9645109 ]\n",
      "   [0.92939806]\n",
      "   [0.9231056 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.16182184]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.1613966 ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.16118069]]]\n",
      "\n",
      "\n",
      " [[[0.814349  ]\n",
      "   [0.9856756 ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   [0.9978009 ]]\n",
      "\n",
      "  [[0.7738697 ]\n",
      "   [0.8994985 ]\n",
      "   [0.8959378 ]\n",
      "   ...\n",
      "   [0.8959378 ]\n",
      "   [0.8959378 ]\n",
      "   [0.89942753]]\n",
      "\n",
      "  [[0.65179914]\n",
      "   [0.588238  ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.3570581 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]]\n",
      "(256, 64, 1)\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 256, 64, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_1 (Conv2D)   (None, 128, 32, 512) 5120        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_1 (ReLU)           (None, 128, 32, 512) 0           encoder_conv_layer_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_1 (BatchNormalizatio (None, 128, 32, 512) 2048        encoder_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_2 (Conv2D)   (None, 64, 16, 256)  1179904     encoder_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_2 (ReLU)           (None, 64, 16, 256)  0           encoder_conv_layer_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_2 (BatchNormalizatio (None, 64, 16, 256)  1024        encoder_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_3 (Conv2D)   (None, 32, 8, 128)   295040      encoder_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_3 (ReLU)           (None, 32, 8, 128)   0           encoder_conv_layer_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_3 (BatchNormalizatio (None, 32, 8, 128)   512         encoder_relu_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_4 (Conv2D)   (None, 16, 4, 64)    73792       encoder_bn_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_4 (ReLU)           (None, 16, 4, 64)    0           encoder_conv_layer_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_4 (BatchNormalizatio (None, 16, 4, 64)    256         encoder_relu_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_5 (Conv2D)   (None, 8, 4, 32)     18464       encoder_bn_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_5 (ReLU)           (None, 8, 4, 32)     0           encoder_conv_layer_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_5 (BatchNormalizatio (None, 8, 4, 32)     128         encoder_relu_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1024)         0           encoder_bn_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 128)          131200      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_variance (Dense)            (None, 128)          131200      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 128)          0           mu[0][0]                         \n",
      "                                                                 log_variance[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,838,688\n",
      "Trainable params: 1,836,704\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "decoder_dense (Dense)        (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 8, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 16, 4, 32)         9248      \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 16, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 16, 4, 32)         128       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 32, 8, 64)         18496     \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 32, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 32, 8, 64)         256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 64, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "decoder_relu_3 (ReLU)        (None, 64, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_3 (BatchNormaliza (None, 64, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 128, 32, 256)      295168    \n",
      "_________________________________________________________________\n",
      "decoder_relu_4 (ReLU)        (None, 128, 32, 256)      0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_4 (BatchNormaliza (None, 128, 32, 256)      1024      \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 256, 64, 1)        2305      \n",
      "_________________________________________________________________\n",
      "sigmoid_layer (Activation)   (None, 256, 64, 1)        0         \n",
      "=================================================================\n",
      "Total params: 533,089\n",
      "Trainable params: 532,129\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 256, 64, 1)]      0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 128)               1838688   \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 256, 64, 1)        533089    \n",
      "=================================================================\n",
      "Total params: 2,371,777\n",
      "Trainable params: 2,368,833\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 09:31:42.939869: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-11-22 09:31:43.139259: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2024-11-22 09:31:43.398416: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2445430000 Hz\n",
      "2024-11-22 09:31:44.302995: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21233664 exceeds 10% of free system memory.\n",
      "2024-11-22 09:31:44.338601: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21233664 exceeds 10% of free system memory.\n",
      "2024-11-22 09:31:44.360760: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21233664 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 09:31:45.512353: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 285212672 exceeds 10% of free system memory.\n",
      "2024-11-22 09:31:45.512353: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 285212672 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 6s 175ms/sample - loss: 1070.9966 - _calculate_reconstruction_loss: 0.2364 - _calculate_kl_loss: 834.5837\n",
      "Epoch 2/150\n",
      "34/34 [==============================] - 5s 140ms/sample - loss: 503.6679 - _calculate_reconstruction_loss: 0.2342 - _calculate_kl_loss: 269.4602\n",
      "Epoch 3/150\n",
      "34/34 [==============================] - 5s 142ms/sample - loss: 376.3226 - _calculate_reconstruction_loss: 0.2377 - _calculate_kl_loss: 138.6281\n",
      "Epoch 4/150\n",
      "34/34 [==============================] - 5s 138ms/sample - loss: 328.1326 - _calculate_reconstruction_loss: 0.2266 - _calculate_kl_loss: 101.5229\n",
      "Epoch 5/150\n",
      "34/34 [==============================] - 5s 139ms/sample - loss: 296.2864 - _calculate_reconstruction_loss: 0.2170 - _calculate_kl_loss: 79.3179\n",
      "Epoch 6/150\n",
      "34/34 [==============================] - 5s 137ms/sample - loss: 267.9529 - _calculate_reconstruction_loss: 0.2038 - _calculate_kl_loss: 64.1779\n",
      "Epoch 7/150\n",
      "34/34 [==============================] - 5s 138ms/sample - loss: 248.2840 - _calculate_reconstruction_loss: 0.1948 - _calculate_kl_loss: 53.4408\n",
      "Epoch 8/150\n",
      "34/34 [==============================] - 5s 137ms/sample - loss: 230.2405 - _calculate_reconstruction_loss: 0.1842 - _calculate_kl_loss: 46.0268\n",
      "Epoch 9/150\n",
      "34/34 [==============================] - 5s 139ms/sample - loss: 217.5828 - _calculate_reconstruction_loss: 0.1761 - _calculate_kl_loss: 41.5084\n",
      "Epoch 10/150\n",
      "34/34 [==============================] - 5s 140ms/sample - loss: 205.6315 - _calculate_reconstruction_loss: 0.1668 - _calculate_kl_loss: 38.8600\n",
      "Epoch 11/150\n",
      "34/34 [==============================] - 5s 137ms/sample - loss: 197.9288 - _calculate_reconstruction_loss: 0.1609 - _calculate_kl_loss: 37.0269\n",
      "Epoch 12/150\n",
      "34/34 [==============================] - 5s 138ms/sample - loss: 189.2221 - _calculate_reconstruction_loss: 0.1538 - _calculate_kl_loss: 35.4697\n",
      "Epoch 13/150\n",
      "34/34 [==============================] - 5s 135ms/sample - loss: 181.1627 - _calculate_reconstruction_loss: 0.1474 - _calculate_kl_loss: 33.7703\n",
      "Epoch 14/150\n",
      "34/34 [==============================] - 5s 132ms/sample - loss: 174.8756 - _calculate_reconstruction_loss: 0.1432 - _calculate_kl_loss: 31.7222\n",
      "Epoch 15/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 164.6624 - _calculate_reconstruction_loss: 0.1350 - _calculate_kl_loss: 29.6384\n",
      "Epoch 16/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 157.3136 - _calculate_reconstruction_loss: 0.1299 - _calculate_kl_loss: 27.4313\n",
      "Epoch 17/150\n",
      "34/34 [==============================] - 5s 135ms/sample - loss: 151.8298 - _calculate_reconstruction_loss: 0.1265 - _calculate_kl_loss: 25.3737\n",
      "Epoch 18/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 144.9994 - _calculate_reconstruction_loss: 0.1215 - _calculate_kl_loss: 23.4703\n",
      "Epoch 19/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 140.9926 - _calculate_reconstruction_loss: 0.1191 - _calculate_kl_loss: 21.9006\n",
      "Epoch 20/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 136.7413 - _calculate_reconstruction_loss: 0.1163 - _calculate_kl_loss: 20.4241\n",
      "Epoch 21/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 128.8488 - _calculate_reconstruction_loss: 0.1094 - _calculate_kl_loss: 19.4807\n",
      "Epoch 22/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 124.3424 - _calculate_reconstruction_loss: 0.1059 - _calculate_kl_loss: 18.4242\n",
      "Epoch 23/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 122.4893 - _calculate_reconstruction_loss: 0.1052 - _calculate_kl_loss: 17.2492\n",
      "Epoch 24/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 117.8304 - _calculate_reconstruction_loss: 0.1017 - _calculate_kl_loss: 16.1452\n",
      "Epoch 25/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 111.9179 - _calculate_reconstruction_loss: 0.0967 - _calculate_kl_loss: 15.2652\n",
      "Epoch 26/150\n",
      "34/34 [==============================] - 5s 135ms/sample - loss: 108.7144 - _calculate_reconstruction_loss: 0.0943 - _calculate_kl_loss: 14.3746\n",
      "Epoch 27/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 105.2297 - _calculate_reconstruction_loss: 0.0917 - _calculate_kl_loss: 13.5108\n",
      "Epoch 28/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 102.3228 - _calculate_reconstruction_loss: 0.0896 - _calculate_kl_loss: 12.7508\n",
      "Epoch 29/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 99.5042 - _calculate_reconstruction_loss: 0.0876 - _calculate_kl_loss: 11.9496\n",
      "Epoch 30/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 97.2707 - _calculate_reconstruction_loss: 0.0862 - _calculate_kl_loss: 11.1167\n",
      "Epoch 31/150\n",
      "34/34 [==============================] - 5s 136ms/sample - loss: 94.4268 - _calculate_reconstruction_loss: 0.0840 - _calculate_kl_loss: 10.4510\n",
      "Epoch 32/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 92.5543 - _calculate_reconstruction_loss: 0.0825 - _calculate_kl_loss: 10.0718\n",
      "Epoch 33/150\n",
      "34/34 [==============================] - 5s 135ms/sample - loss: 89.0302 - _calculate_reconstruction_loss: 0.0791 - _calculate_kl_loss: 9.9781\n",
      "Epoch 34/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 89.2663 - _calculate_reconstruction_loss: 0.0796 - _calculate_kl_loss: 9.6384\n",
      "Epoch 35/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 85.3007 - _calculate_reconstruction_loss: 0.0758 - _calculate_kl_loss: 9.5285\n",
      "Epoch 36/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 84.5745 - _calculate_reconstruction_loss: 0.0754 - _calculate_kl_loss: 9.2067\n",
      "Epoch 37/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 81.5440 - _calculate_reconstruction_loss: 0.0730 - _calculate_kl_loss: 8.5579\n",
      "Epoch 38/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 80.7391 - _calculate_reconstruction_loss: 0.0727 - _calculate_kl_loss: 7.9904\n",
      "Epoch 39/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 77.6584 - _calculate_reconstruction_loss: 0.0700 - _calculate_kl_loss: 7.6674\n",
      "Epoch 40/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 77.2492 - _calculate_reconstruction_loss: 0.0699 - _calculate_kl_loss: 7.3366\n",
      "Epoch 41/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 74.9974 - _calculate_reconstruction_loss: 0.0678 - _calculate_kl_loss: 7.2085\n",
      "Epoch 42/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 73.8392 - _calculate_reconstruction_loss: 0.0667 - _calculate_kl_loss: 7.1825\n",
      "Epoch 43/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 72.9293 - _calculate_reconstruction_loss: 0.0660 - _calculate_kl_loss: 6.9627\n",
      "Epoch 44/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 70.9711 - _calculate_reconstruction_loss: 0.0643 - _calculate_kl_loss: 6.6838\n",
      "Epoch 45/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 69.7578 - _calculate_reconstruction_loss: 0.0633 - _calculate_kl_loss: 6.4437\n",
      "Epoch 46/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 71.0529 - _calculate_reconstruction_loss: 0.0647 - _calculate_kl_loss: 6.3371\n",
      "Epoch 47/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 68.3493 - _calculate_reconstruction_loss: 0.0614 - _calculate_kl_loss: 6.9278\n",
      "Epoch 48/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 67.2675 - _calculate_reconstruction_loss: 0.0599 - _calculate_kl_loss: 7.3456\n",
      "Epoch 49/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 66.4426 - _calculate_reconstruction_loss: 0.0591 - _calculate_kl_loss: 7.3238\n",
      "Epoch 50/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 64.7103 - _calculate_reconstruction_loss: 0.0580 - _calculate_kl_loss: 6.7472\n",
      "Epoch 51/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 63.8484 - _calculate_reconstruction_loss: 0.0580 - _calculate_kl_loss: 5.8806\n",
      "Epoch 52/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 65.7539 - _calculate_reconstruction_loss: 0.0606 - _calculate_kl_loss: 5.1228\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 132ms/sample - loss: 62.8985 - _calculate_reconstruction_loss: 0.0573 - _calculate_kl_loss: 5.5574\n",
      "Epoch 54/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 62.4132 - _calculate_reconstruction_loss: 0.0559 - _calculate_kl_loss: 6.4702\n",
      "Epoch 55/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 61.4552 - _calculate_reconstruction_loss: 0.0544 - _calculate_kl_loss: 7.0607\n",
      "Epoch 56/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 61.4977 - _calculate_reconstruction_loss: 0.0546 - _calculate_kl_loss: 6.9232\n",
      "Epoch 57/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 59.9873 - _calculate_reconstruction_loss: 0.0533 - _calculate_kl_loss: 6.7222\n",
      "Epoch 58/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 58.7731 - _calculate_reconstruction_loss: 0.0526 - _calculate_kl_loss: 6.2016\n",
      "Epoch 59/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 57.7205 - _calculate_reconstruction_loss: 0.0523 - _calculate_kl_loss: 5.4590\n",
      "Epoch 60/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 56.9174 - _calculate_reconstruction_loss: 0.0521 - _calculate_kl_loss: 4.7682\n",
      "Epoch 61/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 56.6380 - _calculate_reconstruction_loss: 0.0523 - _calculate_kl_loss: 4.3142\n",
      "Epoch 62/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 60.3537 - _calculate_reconstruction_loss: 0.0561 - _calculate_kl_loss: 4.2465\n",
      "Epoch 63/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 56.8111 - _calculate_reconstruction_loss: 0.0501 - _calculate_kl_loss: 6.6775\n",
      "Epoch 64/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 59.0988 - _calculate_reconstruction_loss: 0.0492 - _calculate_kl_loss: 9.8927\n",
      "Epoch 65/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 62.1650 - _calculate_reconstruction_loss: 0.0503 - _calculate_kl_loss: 11.8243\n",
      "Epoch 66/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 59.9800 - _calculate_reconstruction_loss: 0.0482 - _calculate_kl_loss: 11.7542\n",
      "Epoch 67/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 57.8698 - _calculate_reconstruction_loss: 0.0477 - _calculate_kl_loss: 10.1501\n",
      "Epoch 68/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 55.2670 - _calculate_reconstruction_loss: 0.0472 - _calculate_kl_loss: 8.0712\n",
      "Epoch 69/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 53.8596 - _calculate_reconstruction_loss: 0.0475 - _calculate_kl_loss: 6.3816\n",
      "Epoch 70/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 55.5211 - _calculate_reconstruction_loss: 0.0501 - _calculate_kl_loss: 5.4380\n",
      "Epoch 71/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 52.9517 - _calculate_reconstruction_loss: 0.0478 - _calculate_kl_loss: 5.1540\n",
      "Epoch 72/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 50.9006 - _calculate_reconstruction_loss: 0.0457 - _calculate_kl_loss: 5.2028\n",
      "Epoch 73/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 51.1648 - _calculate_reconstruction_loss: 0.0458 - _calculate_kl_loss: 5.3617\n",
      "Epoch 74/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 50.5434 - _calculate_reconstruction_loss: 0.0450 - _calculate_kl_loss: 5.4969\n",
      "Epoch 75/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 49.7388 - _calculate_reconstruction_loss: 0.0442 - _calculate_kl_loss: 5.5812\n",
      "Epoch 76/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 50.4251 - _calculate_reconstruction_loss: 0.0451 - _calculate_kl_loss: 5.2816\n",
      "Epoch 77/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 49.0211 - _calculate_reconstruction_loss: 0.0436 - _calculate_kl_loss: 5.3888\n",
      "Epoch 78/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 49.2145 - _calculate_reconstruction_loss: 0.0441 - _calculate_kl_loss: 5.1494\n",
      "Epoch 79/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 48.4919 - _calculate_reconstruction_loss: 0.0438 - _calculate_kl_loss: 4.6815\n",
      "Epoch 80/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 47.0099 - _calculate_reconstruction_loss: 0.0430 - _calculate_kl_loss: 4.0452\n",
      "Epoch 81/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 46.8163 - _calculate_reconstruction_loss: 0.0432 - _calculate_kl_loss: 3.5777\n",
      "Epoch 82/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 49.1121 - _calculate_reconstruction_loss: 0.0457 - _calculate_kl_loss: 3.3667\n",
      "Epoch 83/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 47.3905 - _calculate_reconstruction_loss: 0.0431 - _calculate_kl_loss: 4.2760\n",
      "Epoch 84/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 47.1586 - _calculate_reconstruction_loss: 0.0416 - _calculate_kl_loss: 5.5836\n",
      "Epoch 85/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 48.1448 - _calculate_reconstruction_loss: 0.0416 - _calculate_kl_loss: 6.4998\n",
      "Epoch 86/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 47.6460 - _calculate_reconstruction_loss: 0.0410 - _calculate_kl_loss: 6.6707\n",
      "Epoch 87/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 47.5703 - _calculate_reconstruction_loss: 0.0414 - _calculate_kl_loss: 6.1975\n",
      "Epoch 88/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 45.9535 - _calculate_reconstruction_loss: 0.0404 - _calculate_kl_loss: 5.5056\n",
      "Epoch 89/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 44.9753 - _calculate_reconstruction_loss: 0.0401 - _calculate_kl_loss: 4.8832\n",
      "Epoch 90/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 44.8056 - _calculate_reconstruction_loss: 0.0403 - _calculate_kl_loss: 4.4607\n",
      "Epoch 91/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 46.8455 - _calculate_reconstruction_loss: 0.0426 - _calculate_kl_loss: 4.2356\n",
      "Epoch 92/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 47.2162 - _calculate_reconstruction_loss: 0.0430 - _calculate_kl_loss: 4.2505\n",
      "Epoch 93/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 45.6567 - _calculate_reconstruction_loss: 0.0399 - _calculate_kl_loss: 5.7336\n",
      "Epoch 94/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 47.5364 - _calculate_reconstruction_loss: 0.0396 - _calculate_kl_loss: 7.9627\n",
      "Epoch 95/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 48.5400 - _calculate_reconstruction_loss: 0.0390 - _calculate_kl_loss: 9.5075\n",
      "Epoch 96/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 49.1784 - _calculate_reconstruction_loss: 0.0396 - _calculate_kl_loss: 9.6195\n",
      "Epoch 97/150\n",
      "34/34 [==============================] - 5s 132ms/sample - loss: 46.9605 - _calculate_reconstruction_loss: 0.0384 - _calculate_kl_loss: 8.5220\n",
      "Epoch 98/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 45.5002 - _calculate_reconstruction_loss: 0.0386 - _calculate_kl_loss: 6.9384\n",
      "Epoch 99/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 43.7116 - _calculate_reconstruction_loss: 0.0381 - _calculate_kl_loss: 5.5661\n",
      "Epoch 100/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 42.9801 - _calculate_reconstruction_loss: 0.0383 - _calculate_kl_loss: 4.7224\n",
      "Epoch 101/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 44.5863 - _calculate_reconstruction_loss: 0.0402 - _calculate_kl_loss: 4.3425\n",
      "Epoch 102/150\n",
      "34/34 [==============================] - 5s 132ms/sample - loss: 44.7262 - _calculate_reconstruction_loss: 0.0406 - _calculate_kl_loss: 4.1312\n",
      "Epoch 103/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 45.5031 - _calculate_reconstruction_loss: 0.0409 - _calculate_kl_loss: 4.6435\n",
      "Epoch 104/150\n",
      "34/34 [==============================] - 5s 132ms/sample - loss: 45.7780 - _calculate_reconstruction_loss: 0.0376 - _calculate_kl_loss: 8.1709\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 132ms/sample - loss: 49.6621 - _calculate_reconstruction_loss: 0.0370 - _calculate_kl_loss: 12.6873\n",
      "Epoch 106/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 52.7075 - _calculate_reconstruction_loss: 0.0369 - _calculate_kl_loss: 15.7842\n",
      "Epoch 107/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 53.3133 - _calculate_reconstruction_loss: 0.0369 - _calculate_kl_loss: 16.3650\n",
      "Epoch 108/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 51.0456 - _calculate_reconstruction_loss: 0.0363 - _calculate_kl_loss: 14.7495\n",
      "Epoch 109/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 48.9320 - _calculate_reconstruction_loss: 0.0369 - _calculate_kl_loss: 12.0603\n",
      "Epoch 110/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 45.4926 - _calculate_reconstruction_loss: 0.0361 - _calculate_kl_loss: 9.4288\n",
      "Epoch 111/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 43.1449 - _calculate_reconstruction_loss: 0.0356 - _calculate_kl_loss: 7.5456\n",
      "Epoch 112/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 42.5014 - _calculate_reconstruction_loss: 0.0360 - _calculate_kl_loss: 6.5092\n",
      "Epoch 113/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 41.7804 - _calculate_reconstruction_loss: 0.0358 - _calculate_kl_loss: 6.0127\n",
      "Epoch 114/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 46.9198 - _calculate_reconstruction_loss: 0.0414 - _calculate_kl_loss: 5.4898\n",
      "Epoch 115/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 40.1447 - _calculate_reconstruction_loss: 0.0352 - _calculate_kl_loss: 4.9485\n",
      "Epoch 116/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 40.4084 - _calculate_reconstruction_loss: 0.0353 - _calculate_kl_loss: 5.0912\n",
      "Epoch 117/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 40.9263 - _calculate_reconstruction_loss: 0.0349 - _calculate_kl_loss: 6.0116\n",
      "Epoch 118/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 41.5050 - _calculate_reconstruction_loss: 0.0346 - _calculate_kl_loss: 6.9468\n",
      "Epoch 119/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 41.5882 - _calculate_reconstruction_loss: 0.0342 - _calculate_kl_loss: 7.3575\n",
      "Epoch 120/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 41.4912 - _calculate_reconstruction_loss: 0.0344 - _calculate_kl_loss: 7.0752\n",
      "Epoch 121/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 40.7527 - _calculate_reconstruction_loss: 0.0345 - _calculate_kl_loss: 6.2465\n",
      "Epoch 122/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 39.4154 - _calculate_reconstruction_loss: 0.0342 - _calculate_kl_loss: 5.1755\n",
      "Epoch 123/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 38.1006 - _calculate_reconstruction_loss: 0.0339 - _calculate_kl_loss: 4.1731\n",
      "Epoch 124/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 37.3345 - _calculate_reconstruction_loss: 0.0339 - _calculate_kl_loss: 3.4660\n",
      "Epoch 125/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 41.3498 - _calculate_reconstruction_loss: 0.0383 - _calculate_kl_loss: 3.0938\n",
      "Epoch 126/150\n",
      "34/34 [==============================] - 5s 132ms/sample - loss: 37.2823 - _calculate_reconstruction_loss: 0.0339 - _calculate_kl_loss: 3.3953\n",
      "Epoch 127/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 37.3313 - _calculate_reconstruction_loss: 0.0331 - _calculate_kl_loss: 4.2668\n",
      "Epoch 128/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 38.3395 - _calculate_reconstruction_loss: 0.0332 - _calculate_kl_loss: 5.1359\n",
      "Epoch 129/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 38.5107 - _calculate_reconstruction_loss: 0.0329 - _calculate_kl_loss: 5.5826\n",
      "Epoch 130/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 38.7431 - _calculate_reconstruction_loss: 0.0333 - _calculate_kl_loss: 5.4924\n",
      "Epoch 131/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 37.5412 - _calculate_reconstruction_loss: 0.0325 - _calculate_kl_loss: 5.0229\n",
      "Epoch 132/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 37.0845 - _calculate_reconstruction_loss: 0.0327 - _calculate_kl_loss: 4.3832\n",
      "Epoch 133/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 36.7381 - _calculate_reconstruction_loss: 0.0330 - _calculate_kl_loss: 3.7617\n",
      "Epoch 134/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 37.5800 - _calculate_reconstruction_loss: 0.0343 - _calculate_kl_loss: 3.2471\n",
      "Epoch 135/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 36.7231 - _calculate_reconstruction_loss: 0.0337 - _calculate_kl_loss: 3.0404\n",
      "Epoch 136/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 35.7204 - _calculate_reconstruction_loss: 0.0325 - _calculate_kl_loss: 3.1955\n",
      "Epoch 137/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 35.6805 - _calculate_reconstruction_loss: 0.0323 - _calculate_kl_loss: 3.4297\n",
      "Epoch 138/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 36.5052 - _calculate_reconstruction_loss: 0.0330 - _calculate_kl_loss: 3.5310\n",
      "Epoch 139/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 40.6716 - _calculate_reconstruction_loss: 0.0369 - _calculate_kl_loss: 3.8149\n",
      "Epoch 140/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 37.4707 - _calculate_reconstruction_loss: 0.0320 - _calculate_kl_loss: 5.4882\n",
      "Epoch 141/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 39.0403 - _calculate_reconstruction_loss: 0.0320 - _calculate_kl_loss: 7.0741\n",
      "Epoch 142/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 40.4092 - _calculate_reconstruction_loss: 0.0325 - _calculate_kl_loss: 7.9183\n",
      "Epoch 143/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 39.5549 - _calculate_reconstruction_loss: 0.0317 - _calculate_kl_loss: 7.8416\n",
      "Epoch 144/150\n",
      "34/34 [==============================] - 4s 131ms/sample - loss: 38.7954 - _calculate_reconstruction_loss: 0.0318 - _calculate_kl_loss: 7.0230\n",
      "Epoch 145/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 37.3723 - _calculate_reconstruction_loss: 0.0315 - _calculate_kl_loss: 5.8604\n",
      "Epoch 146/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 36.3823 - _calculate_reconstruction_loss: 0.0317 - _calculate_kl_loss: 4.7263\n",
      "Epoch 147/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 35.7105 - _calculate_reconstruction_loss: 0.0319 - _calculate_kl_loss: 3.8580\n",
      "Epoch 148/150\n",
      "34/34 [==============================] - 5s 134ms/sample - loss: 35.5968 - _calculate_reconstruction_loss: 0.0323 - _calculate_kl_loss: 3.3190\n",
      "Epoch 149/150\n",
      "34/34 [==============================] - 4s 132ms/sample - loss: 35.4618 - _calculate_reconstruction_loss: 0.0325 - _calculate_kl_loss: 2.9431\n",
      "Epoch 150/150\n",
      "34/34 [==============================] - 5s 133ms/sample - loss: 37.5873 - _calculate_reconstruction_loss: 0.0349 - _calculate_kl_loss: 2.7196\n"
     ]
    }
   ],
   "source": [
    "x_train = load_fsdd(SPECTROGRAMS_PATH)\n",
    "autoencoder = train(x_train, LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "autoencoder.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
