{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 16:58:55.820890: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-11-22 16:58:55.820919: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.0\n",
      "Keras version: 2.4.0\n",
      "GPU is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 16:58:56.776772: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-11-22 16:58:56.776928: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-11-22 16:58:56.776942: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-11-22 16:58:56.776963: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-c8a454): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda, Cropping2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from midi2audio import FluidSynth\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_wav(midi_file, wav_file, soundfont_path):\n",
    "    fs = FluidSynth(soundfont_path)  # Load the soundfont\n",
    "    fs.midi_to_audio(midi_file, wav_file)  # Convert MIDI to WAV\n",
    "    print(f\"Converted {midi_file} to {wav_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'FluidR3_GM.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4507/1574302963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmidi_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwav_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"sound_file_{sound_file_counter}.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmidi_to_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoundfont_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msound_file_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4507/74502128.py\u001b[0m in \u001b[0;36mmidi_to_wav\u001b[0;34m(midi_file, wav_file, soundfont_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmidi_to_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoundfont_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFluidSynth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoundfont_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the soundfont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi_to_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert MIDI to WAV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Converted {midi_file} to {wav_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/site-packages/midi2audio.py\u001b[0m in \u001b[0;36mmidi_to_audio\u001b[0;34m(self, midi_file, audio_file)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmidi_to_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fluidsynth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-ni'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msound_font\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sound_file_counter = 0\n",
    "soundfont_path = \"FluidR3_GM.sf2\"\n",
    "wav_path = \"maestro_dataset/mp3/\"\n",
    "\n",
    "for path, _ , file_names in os.walk('maestro_dataset/midi'):\n",
    "    for file_name in file_names:\n",
    "        midi_file = os.path.join(path, file_name)\n",
    "        wav_file = os.path.join(wav_path, f\"sound_file_{sound_file_counter}.wav\")\n",
    "        midi_to_wav(midi_file, wav_file, soundfont_path)\n",
    "\n",
    "        sound_file_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    \"\"\"Loader is responsible for loading an audio file.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, duration, mono):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.mono = mono\n",
    "\n",
    "    def load(self, file_path):\n",
    "        signal = librosa.load(file_path,\n",
    "                              sr=self.sample_rate,\n",
    "                              duration=self.duration,\n",
    "                              mono=self.mono)[0]\n",
    "        return signal\n",
    "\n",
    "class Padder:\n",
    "    \"\"\"Padder is responsible to apply padding to an array.\"\"\"\n",
    "\n",
    "    def __init__(self, mode=\"constant\"):\n",
    "        self.mode = mode\n",
    "\n",
    "    def left_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (num_missing_items, 0),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "    def right_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (0, num_missing_items),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "\n",
    "class LogSpectrogramExtractor:\n",
    "    \"\"\"LogSpectrogramExtractor extracts log spectrograms (in dB) from a\n",
    "    time-series signal.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frame_size, hop_length):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def extract(self, signal):\n",
    "        stft = librosa.stft(signal,\n",
    "                            n_fft=self.frame_size,\n",
    "                            hop_length=self.hop_length)[:-1]\n",
    "        spectrogram = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "        return log_spectrogram\n",
    "\n",
    "\n",
    "class MinMaxNormaliser:\n",
    "    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n",
    "\n",
    "    def __init__(self, min_val, max_val):\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "\n",
    "    def normalise(self, array):\n",
    "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
    "        norm_array = norm_array * (self.max - self.min) + self.min\n",
    "        return norm_array\n",
    "\n",
    "    def denormalise(self, norm_array, original_min, original_max):\n",
    "        array = (norm_array - self.min) / (self.max - self.min)\n",
    "        array = array * (original_max - original_min) + original_min\n",
    "        return array\n",
    "\n",
    "\n",
    "class Saver:\n",
    "    \"\"\"saver is responsible to save features, and the min max values.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
    "        self.feature_save_dir = feature_save_dir\n",
    "        self.min_max_values_save_dir = min_max_values_save_dir\n",
    "\n",
    "    def save_feature(self, feature, file_path):\n",
    "        save_path = self._generate_save_path(file_path)\n",
    "        np.save(save_path, feature)\n",
    "        return save_path\n",
    "\n",
    "    def save_min_max_values(self, min_max_values):\n",
    "        save_path = os.path.join(self.min_max_values_save_dir,\n",
    "                                 \"min_max_values.pkl\")\n",
    "        self._save(min_max_values, save_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _save(data, save_path):\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def _generate_save_path(self, file_path):\n",
    "        file_name = os.path.split(file_path)[1]\n",
    "        save_path = os.path.join(self.feature_save_dir, file_name + \".npy\")\n",
    "        return save_path\n",
    "\n",
    "\n",
    "class PreprocessingPipeline:\n",
    "    \"\"\"PreprocessingPipeline processes audio files in a directory, applying\n",
    "    the following steps to each file:\n",
    "        1- load a file\n",
    "        2- pad the signal (if necessary)\n",
    "        3- extracting log spectrogram from signal\n",
    "        4- normalise spectrogram\n",
    "        5- save the normalised spectrogram\n",
    "\n",
    "    Storing the min max values for all the log spectrograms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.padder = None\n",
    "        self.extractor = None\n",
    "        self.normaliser = None\n",
    "        self.saver = None\n",
    "        self.min_max_values = {}\n",
    "        self._loader = None\n",
    "        self._num_expected_samples = None\n",
    "\n",
    "    @property\n",
    "    def loader(self):\n",
    "        return self._loader\n",
    "\n",
    "    @loader.setter\n",
    "    def loader(self, loader):\n",
    "        self._loader = loader\n",
    "        self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
    "\n",
    "    def process(self, audio_files_dir):\n",
    "        for root, _, files in os.walk(audio_files_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                self._process_file(file_path)\n",
    "                print(f\"Processed file {file_path}\")\n",
    "        self.saver.save_min_max_values(self.min_max_values)\n",
    "\n",
    "    def _process_file(self, file_path):\n",
    "        signal = self.loader.load(file_path)\n",
    "        if self._is_padding_necessary(signal):\n",
    "            signal = self._apply_padding(signal)\n",
    "        feature = self.extractor.extract(signal)\n",
    "        norm_feature = self.normaliser.normalise(feature)\n",
    "        save_path = self.saver.save_feature(norm_feature, file_path)\n",
    "        self._store_min_max_value(save_path, feature.min(), feature.max())\n",
    "\n",
    "    def _is_padding_necessary(self, signal):\n",
    "        if len(signal) < self._num_expected_samples:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _apply_padding(self, signal):\n",
    "        num_missing_samples = self._num_expected_samples - len(signal)\n",
    "        padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
    "        return padded_signal\n",
    "\n",
    "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
    "        self.min_max_values[save_path] = {\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file maestro_dataset/mp3/sound_file_21.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_14.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_27.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_15.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_17.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_8.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_6.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_19.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_20.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_13.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_23.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_3.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_33.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_12.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_5.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_0.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_10.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_31.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_16.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_9.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_18.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_22.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_11.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_1.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_2.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_24.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_28.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_25.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_7.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_4.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_30.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_26.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_29.wav\n",
      "Processed file maestro_dataset/mp3/sound_file_32.wav\n"
     ]
    }
   ],
   "source": [
    "# FRAME_SIZE = 512\n",
    "# HOP_LENGTH = 256\n",
    "# DURATION = 30.0  # in seconds\n",
    "# SAMPLE_RATE = 22050\n",
    "# MONO = True\n",
    "\n",
    "# SPECTROGRAMS_SAVE_DIR = \"maestro_dataset/spectograms\"\n",
    "# MIN_MAX_VALUES_SAVE_DIR = \"maestro_dataset/minmax\"\n",
    "# FILES_DIR = \"maestro_dataset/mp3\"\n",
    "\n",
    "# # instantiate all objects\n",
    "# loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "# padder = Padder()\n",
    "# log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "# min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "# saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
    "\n",
    "# preprocessing_pipeline = PreprocessingPipeline()\n",
    "# preprocessing_pipeline.loader = loader\n",
    "# preprocessing_pipeline.padder = padder\n",
    "# preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
    "# preprocessing_pipeline.normaliser = min_max_normaliser\n",
    "# preprocessing_pipeline.saver = saver\n",
    "\n",
    "# preprocessing_pipeline.process(FILES_DIR)\n",
    "\n",
    "FRAME_SIZE = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 4.5  # in seconds\n",
    "SAMPLE_RATE = 22050\n",
    "MONO = True\n",
    "\n",
    "SPECTROGRAMS_SAVE_DIR = \"maestro_dataset/spectograms\"\n",
    "MIN_MAX_VALUES_SAVE_DIR = \"maestro_dataset/minmax\"\n",
    "FILES_DIR = \"maestro_dataset/mp3\"\n",
    "\n",
    "# instantiate all objects\n",
    "loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "padder = Padder()\n",
    "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
    "\n",
    "preprocessing_pipeline = PreprocessingPipeline()\n",
    "preprocessing_pipeline.loader = loader\n",
    "preprocessing_pipeline.padder = padder\n",
    "preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
    "preprocessing_pipeline.normaliser = min_max_normaliser\n",
    "preprocessing_pipeline.saver = saver\n",
    "\n",
    "preprocessing_pipeline.process(FILES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_reconstruction_loss(y_target, y_predicted):\n",
    "    error = y_target - y_predicted\n",
    "    reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def calculate_kl_loss(model):\n",
    "    # wrap `_calculate_kl_loss` such that it takes the model as an argument,\n",
    "    # returns a function which can take arbitrary number of arguments\n",
    "    # (for compatibility with `metrics` and utility in the loss function)\n",
    "    # and returns the kl loss\n",
    "    def _calculate_kl_loss(*args):\n",
    "        kl_loss = -0.5 * K.sum(1 + model.log_variance - K.square(model.mu) -\n",
    "                               K.exp(model.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "    return _calculate_kl_loss\n",
    "\n",
    "\n",
    "class VAE:\n",
    "    \"\"\"\n",
    "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
    "    with mirrored encoder and decoder components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 conv_filters,\n",
    "                 conv_kernels,\n",
    "                 conv_strides,\n",
    "                 latent_space_dim):\n",
    "        self.input_shape = input_shape # [28, 28, 1]\n",
    "        self.conv_filters = conv_filters # [2, 4, 8]\n",
    "        self.conv_kernels = conv_kernels # [3, 5, 3]\n",
    "        self.conv_strides = conv_strides # [1, 2, 2]\n",
    "        self.latent_space_dim = latent_space_dim # 2\n",
    "        self.reconstruction_loss_weight = 1000\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=self._calculate_combined_loss,\n",
    "                           metrics=[_calculate_reconstruction_loss,\n",
    "                                    calculate_kl_loss(self)])\n",
    "\n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        self.model.fit(x_train,\n",
    "                       x_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       shuffle=True)\n",
    "\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = VAE(*parameters)\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
    "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
    "                                                         + kl_loss\n",
    "        return combined_loss\n",
    "\n",
    "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
    "        error = y_target - y_predicted\n",
    "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "        return reconstruction_loss\n",
    "\n",
    "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
    "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
    "                               K.exp(self.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(parameters, f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.model.save_weights(save_path)\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "\n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "\n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "\n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        \"\"\"Add conv transpose blocks.\"\"\"\n",
    "        # loop through all the conv layers in reverse order and stop at the\n",
    "        # first layer\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=self.conv_kernels[0],\n",
    "            strides=self.conv_strides[0],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = Cropping2D(cropping=((0, 0), (0, 12)))(x)  # Adjust crop values as needed\n",
    "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
    "        return output_layer\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "\n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
    "        x = encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
    "        conv 2d + ReLU + batch normalization.\n",
    "        \"\"\"\n",
    "        layer_number = layer_index + 1\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_bottleneck(self, x):\n",
    "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
    "        layer).\n",
    "        \"\"\"\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
    "        self.log_variance = Dense(self.latent_space_dim,\n",
    "                                  name=\"log_variance\")(x)\n",
    "\n",
    "        def sample_point_from_normal_distribution(args):\n",
    "            mu, log_variance = args\n",
    "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
    "                                      stddev=1.)\n",
    "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
    "            return sampled_point\n",
    "\n",
    "        print(self.input_shape)\n",
    "\n",
    "        x = Lambda(sample_point_from_normal_distribution,\n",
    "               name=\"encoder_output\")([self.mu, self.log_variance])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 150\n",
    "\n",
    "SPECTROGRAMS_PATH = \"maestro_dataset/spectograms\"\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 64, 1)\n",
    "    return x_train\n",
    "\n",
    "\n",
    "def train(x_train, learning_rate, batch_size, epochs):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(256, 388, 1),\n",
    "        conv_filters=(512, 256, 128, 64, 32),\n",
    "        conv_kernels=(3, 3, 3, 3, 3),\n",
    "        conv_strides=(2, 2, 2, 2, (2, 1)),\n",
    "        latent_space_dim=128\n",
    "    )\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, epochs)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 388, 1)\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 256, 388, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_1 (Conv2D)   (None, 128, 194, 512 5120        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_1 (ReLU)           (None, 128, 194, 512 0           encoder_conv_layer_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_1 (BatchNormalizatio (None, 128, 194, 512 2048        encoder_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_2 (Conv2D)   (None, 64, 97, 256)  1179904     encoder_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_2 (ReLU)           (None, 64, 97, 256)  0           encoder_conv_layer_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_2 (BatchNormalizatio (None, 64, 97, 256)  1024        encoder_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_3 (Conv2D)   (None, 32, 49, 128)  295040      encoder_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_3 (ReLU)           (None, 32, 49, 128)  0           encoder_conv_layer_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_3 (BatchNormalizatio (None, 32, 49, 128)  512         encoder_relu_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_4 (Conv2D)   (None, 16, 25, 64)   73792       encoder_bn_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_4 (ReLU)           (None, 16, 25, 64)   0           encoder_conv_layer_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_4 (BatchNormalizatio (None, 16, 25, 64)   256         encoder_relu_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_5 (Conv2D)   (None, 8, 25, 32)    18464       encoder_bn_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_5 (ReLU)           (None, 8, 25, 32)    0           encoder_conv_layer_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_5 (BatchNormalizatio (None, 8, 25, 32)    128         encoder_relu_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6400)         0           encoder_bn_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 128)          819328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_variance (Dense)            (None, 128)          819328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 128)          0           mu[0][0]                         \n",
      "                                                                 log_variance[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,214,944\n",
      "Trainable params: 3,212,960\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "decoder_dense (Dense)        (None, 6400)              825600    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 25, 32)         0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 16, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 16, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 16, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 32, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 32, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 32, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 64, 100, 128)      73856     \n",
      "_________________________________________________________________\n",
      "decoder_relu_3 (ReLU)        (None, 64, 100, 128)      0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_3 (BatchNormaliza (None, 64, 100, 128)      512       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 128, 200, 256)     295168    \n",
      "_________________________________________________________________\n",
      "decoder_relu_4 (ReLU)        (None, 128, 200, 256)     0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_4 (BatchNormaliza (None, 128, 200, 256)     1024      \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 256, 400, 1)       2305      \n",
      "_________________________________________________________________\n",
      "cropping2d (Cropping2D)      (None, 256, 388, 1)       0         \n",
      "_________________________________________________________________\n",
      "sigmoid_layer (Activation)   (None, 256, 388, 1)       0         \n",
      "=================================================================\n",
      "Total params: 1,226,593\n",
      "Trainable params: 1,225,633\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 256, 388, 1)]     0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 128)               3214944   \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 256, 388, 1)       1226593   \n",
      "=================================================================\n",
      "Total params: 4,441,537\n",
      "Trainable params: 4,438,593\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n",
      "Train on 34 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 16:59:21.185453: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-11-22 16:59:21.253684: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2024-11-22 16:59:21.315049: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2445430000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "34/34 [==============================] - 27s 786ms/sample - loss: 408.6498 - _calculate_reconstruction_loss: 0.2056 - _calculate_kl_loss: 203.0940\n",
      "Epoch 2/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 342.3555 - _calculate_reconstruction_loss: 0.1946 - _calculate_kl_loss: 147.7439\n",
      "Epoch 3/150\n",
      "34/34 [==============================] - 26s 778ms/sample - loss: 290.8146 - _calculate_reconstruction_loss: 0.1877 - _calculate_kl_loss: 103.1449\n",
      "Epoch 4/150\n",
      "34/34 [==============================] - 27s 781ms/sample - loss: 259.6689 - _calculate_reconstruction_loss: 0.1793 - _calculate_kl_loss: 80.3504\n",
      "Epoch 5/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 235.0218 - _calculate_reconstruction_loss: 0.1750 - _calculate_kl_loss: 59.9857\n",
      "Epoch 6/150\n",
      "34/34 [==============================] - 26s 772ms/sample - loss: 221.3796 - _calculate_reconstruction_loss: 0.1695 - _calculate_kl_loss: 51.9161\n",
      "Epoch 7/150\n",
      "34/34 [==============================] - 27s 787ms/sample - loss: 204.6149 - _calculate_reconstruction_loss: 0.1611 - _calculate_kl_loss: 43.4814\n",
      "Epoch 8/150\n",
      "34/34 [==============================] - 27s 795ms/sample - loss: 196.9467 - _calculate_reconstruction_loss: 0.1484 - _calculate_kl_loss: 48.5139\n",
      "Epoch 9/150\n",
      "34/34 [==============================] - 27s 792ms/sample - loss: 180.5178 - _calculate_reconstruction_loss: 0.1478 - _calculate_kl_loss: 32.7102\n",
      "Epoch 10/150\n",
      "34/34 [==============================] - 27s 789ms/sample - loss: 171.0539 - _calculate_reconstruction_loss: 0.1304 - _calculate_kl_loss: 40.6354\n",
      "Epoch 11/150\n",
      "34/34 [==============================] - 26s 771ms/sample - loss: 159.6786 - _calculate_reconstruction_loss: 0.1225 - _calculate_kl_loss: 37.2006\n",
      "Epoch 12/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 143.8422 - _calculate_reconstruction_loss: 0.1130 - _calculate_kl_loss: 30.8746\n",
      "Epoch 13/150\n",
      "34/34 [==============================] - 26s 772ms/sample - loss: 132.2974 - _calculate_reconstruction_loss: 0.0970 - _calculate_kl_loss: 35.2591\n",
      "Epoch 14/150\n",
      "34/34 [==============================] - 26s 773ms/sample - loss: 121.1186 - _calculate_reconstruction_loss: 0.0934 - _calculate_kl_loss: 27.7277\n",
      "Epoch 15/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 131.0925 - _calculate_reconstruction_loss: 0.0842 - _calculate_kl_loss: 46.9305\n",
      "Epoch 16/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 109.3757 - _calculate_reconstruction_loss: 0.0756 - _calculate_kl_loss: 33.7671\n",
      "Epoch 17/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 107.6276 - _calculate_reconstruction_loss: 0.0707 - _calculate_kl_loss: 36.8983\n",
      "Epoch 18/150\n",
      "34/34 [==============================] - 26s 779ms/sample - loss: 105.5505 - _calculate_reconstruction_loss: 0.0620 - _calculate_kl_loss: 43.5670\n",
      "Epoch 19/150\n",
      "34/34 [==============================] - 27s 794ms/sample - loss: 95.7086 - _calculate_reconstruction_loss: 0.0644 - _calculate_kl_loss: 31.2759\n",
      "Epoch 20/150\n",
      "34/34 [==============================] - 27s 789ms/sample - loss: 99.8041 - _calculate_reconstruction_loss: 0.0553 - _calculate_kl_loss: 44.5499\n",
      "Epoch 21/150\n",
      "34/34 [==============================] - 27s 792ms/sample - loss: 84.1273 - _calculate_reconstruction_loss: 0.0565 - _calculate_kl_loss: 27.6235\n",
      "Epoch 22/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 89.9975 - _calculate_reconstruction_loss: 0.0505 - _calculate_kl_loss: 39.4976\n",
      "Epoch 23/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 79.0520 - _calculate_reconstruction_loss: 0.0499 - _calculate_kl_loss: 29.1514\n",
      "Epoch 24/150\n",
      "34/34 [==============================] - 27s 782ms/sample - loss: 79.5023 - _calculate_reconstruction_loss: 0.0453 - _calculate_kl_loss: 34.1835\n",
      "Epoch 25/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 70.7851 - _calculate_reconstruction_loss: 0.0476 - _calculate_kl_loss: 23.2257\n",
      "Epoch 26/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 69.5892 - _calculate_reconstruction_loss: 0.0444 - _calculate_kl_loss: 25.2101\n",
      "Epoch 27/150\n",
      "34/34 [==============================] - 26s 779ms/sample - loss: 66.2119 - _calculate_reconstruction_loss: 0.0423 - _calculate_kl_loss: 23.8797\n",
      "Epoch 28/150\n",
      "34/34 [==============================] - 26s 778ms/sample - loss: 62.0326 - _calculate_reconstruction_loss: 0.0438 - _calculate_kl_loss: 18.2135\n",
      "Epoch 29/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 65.2903 - _calculate_reconstruction_loss: 0.0384 - _calculate_kl_loss: 26.9148\n",
      "Epoch 30/150\n",
      "34/34 [==============================] - 27s 792ms/sample - loss: 56.5902 - _calculate_reconstruction_loss: 0.0402 - _calculate_kl_loss: 16.4003\n",
      "Epoch 31/150\n",
      "34/34 [==============================] - 27s 789ms/sample - loss: 55.8959 - _calculate_reconstruction_loss: 0.0364 - _calculate_kl_loss: 19.5193\n",
      "Epoch 32/150\n",
      "34/34 [==============================] - 27s 793ms/sample - loss: 51.3800 - _calculate_reconstruction_loss: 0.0368 - _calculate_kl_loss: 14.5419\n",
      "Epoch 33/150\n",
      "34/34 [==============================] - 27s 781ms/sample - loss: 52.8474 - _calculate_reconstruction_loss: 0.0410 - _calculate_kl_loss: 11.8588\n",
      "Epoch 34/150\n",
      "34/34 [==============================] - 27s 781ms/sample - loss: 50.1953 - _calculate_reconstruction_loss: 0.0327 - _calculate_kl_loss: 17.4513\n",
      "Epoch 35/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 46.3786 - _calculate_reconstruction_loss: 0.0375 - _calculate_kl_loss: 8.9251\n",
      "Epoch 36/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 44.9881 - _calculate_reconstruction_loss: 0.0332 - _calculate_kl_loss: 11.8315\n",
      "Epoch 37/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 42.5495 - _calculate_reconstruction_loss: 0.0307 - _calculate_kl_loss: 11.8775\n",
      "Epoch 38/150\n",
      "34/34 [==============================] - 26s 766ms/sample - loss: 43.0368 - _calculate_reconstruction_loss: 0.0347 - _calculate_kl_loss: 8.3621\n",
      "Epoch 39/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 41.7752 - _calculate_reconstruction_loss: 0.0301 - _calculate_kl_loss: 11.7027\n",
      "Epoch 40/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 38.5420 - _calculate_reconstruction_loss: 0.0317 - _calculate_kl_loss: 6.8447\n",
      "Epoch 41/150\n",
      "34/34 [==============================] - 27s 787ms/sample - loss: 40.2187 - _calculate_reconstruction_loss: 0.0284 - _calculate_kl_loss: 11.8111\n",
      "Epoch 42/150\n",
      "34/34 [==============================] - 27s 797ms/sample - loss: 38.8522 - _calculate_reconstruction_loss: 0.0321 - _calculate_kl_loss: 6.7307\n",
      "Epoch 43/150\n",
      "34/34 [==============================] - 27s 789ms/sample - loss: 38.4576 - _calculate_reconstruction_loss: 0.0265 - _calculate_kl_loss: 11.9137\n",
      "Epoch 44/150\n",
      "34/34 [==============================] - 27s 796ms/sample - loss: 36.3495 - _calculate_reconstruction_loss: 0.0292 - _calculate_kl_loss: 7.1204\n",
      "Epoch 45/150\n",
      "34/34 [==============================] - 26s 776ms/sample - loss: 37.1509 - _calculate_reconstruction_loss: 0.0279 - _calculate_kl_loss: 9.2212\n",
      "Epoch 46/150\n",
      "34/34 [==============================] - 27s 784ms/sample - loss: 34.3548 - _calculate_reconstruction_loss: 0.0252 - _calculate_kl_loss: 9.1903\n",
      "Epoch 47/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 36.2583 - _calculate_reconstruction_loss: 0.0285 - _calculate_kl_loss: 7.7765\n",
      "Epoch 48/150\n",
      "34/34 [==============================] - 26s 776ms/sample - loss: 33.4446 - _calculate_reconstruction_loss: 0.0236 - _calculate_kl_loss: 9.8618\n",
      "Epoch 49/150\n",
      "34/34 [==============================] - 26s 767ms/sample - loss: 33.5708 - _calculate_reconstruction_loss: 0.0239 - _calculate_kl_loss: 9.6299\n",
      "Epoch 50/150\n",
      "34/34 [==============================] - 26s 768ms/sample - loss: 33.0278 - _calculate_reconstruction_loss: 0.0227 - _calculate_kl_loss: 10.2825\n",
      "Epoch 51/150\n",
      "34/34 [==============================] - 26s 769ms/sample - loss: 33.0710 - _calculate_reconstruction_loss: 0.0215 - _calculate_kl_loss: 11.5241\n",
      "Epoch 52/150\n",
      "34/34 [==============================] - 27s 779ms/sample - loss: 31.6138 - _calculate_reconstruction_loss: 0.0246 - _calculate_kl_loss: 7.0286\n",
      "Epoch 53/150\n",
      "34/34 [==============================] - 27s 792ms/sample - loss: 31.3200 - _calculate_reconstruction_loss: 0.0226 - _calculate_kl_loss: 8.7637\n",
      "Epoch 54/150\n",
      "34/34 [==============================] - 27s 796ms/sample - loss: 29.5707 - _calculate_reconstruction_loss: 0.0220 - _calculate_kl_loss: 7.5983\n",
      "Epoch 55/150\n",
      "34/34 [==============================] - 27s 791ms/sample - loss: 30.8474 - _calculate_reconstruction_loss: 0.0247 - _calculate_kl_loss: 6.1431\n",
      "Epoch 56/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 31.0972 - _calculate_reconstruction_loss: 0.0211 - _calculate_kl_loss: 10.0161\n",
      "Epoch 57/150\n",
      "34/34 [==============================] - 26s 767ms/sample - loss: 28.5987 - _calculate_reconstruction_loss: 0.0215 - _calculate_kl_loss: 7.1233\n",
      "Epoch 58/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 27.8393 - _calculate_reconstruction_loss: 0.0211 - _calculate_kl_loss: 6.7225\n",
      "Epoch 59/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 35.4793 - _calculate_reconstruction_loss: 0.0202 - _calculate_kl_loss: 15.2331\n",
      "Epoch 60/150\n",
      "34/34 [==============================] - 26s 768ms/sample - loss: 33.4018 - _calculate_reconstruction_loss: 0.0247 - _calculate_kl_loss: 8.7254\n",
      "Epoch 61/150\n",
      "34/34 [==============================] - 26s 776ms/sample - loss: 31.6281 - _calculate_reconstruction_loss: 0.0203 - _calculate_kl_loss: 11.3384\n",
      "Epoch 62/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 29.4020 - _calculate_reconstruction_loss: 0.0228 - _calculate_kl_loss: 6.6390\n",
      "Epoch 63/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 32.5730 - _calculate_reconstruction_loss: 0.0194 - _calculate_kl_loss: 13.1928\n",
      "Epoch 64/150\n",
      "34/34 [==============================] - 27s 792ms/sample - loss: 29.5387 - _calculate_reconstruction_loss: 0.0229 - _calculate_kl_loss: 6.6845\n",
      "Epoch 65/150\n",
      "34/34 [==============================] - 27s 801ms/sample - loss: 27.6774 - _calculate_reconstruction_loss: 0.0201 - _calculate_kl_loss: 7.5733\n",
      "Epoch 66/150\n",
      "34/34 [==============================] - 27s 790ms/sample - loss: 26.6981 - _calculate_reconstruction_loss: 0.0210 - _calculate_kl_loss: 5.6599\n",
      "Epoch 67/150\n",
      "34/34 [==============================] - 26s 778ms/sample - loss: 26.4666 - _calculate_reconstruction_loss: 0.0204 - _calculate_kl_loss: 6.0364\n",
      "Epoch 68/150\n",
      "34/34 [==============================] - 26s 779ms/sample - loss: 26.4294 - _calculate_reconstruction_loss: 0.0199 - _calculate_kl_loss: 6.5301\n",
      "Epoch 69/150\n",
      "34/34 [==============================] - 26s 779ms/sample - loss: 26.5158 - _calculate_reconstruction_loss: 0.0199 - _calculate_kl_loss: 6.5934\n",
      "Epoch 70/150\n",
      "34/34 [==============================] - 26s 776ms/sample - loss: 27.1796 - _calculate_reconstruction_loss: 0.0202 - _calculate_kl_loss: 6.9425\n",
      "Epoch 71/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 27.3181 - _calculate_reconstruction_loss: 0.0209 - _calculate_kl_loss: 6.3740\n",
      "Epoch 72/150\n",
      "34/34 [==============================] - 27s 787ms/sample - loss: 28.4445 - _calculate_reconstruction_loss: 0.0199 - _calculate_kl_loss: 8.4955\n",
      "Epoch 73/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 28.3522 - _calculate_reconstruction_loss: 0.0227 - _calculate_kl_loss: 5.6335\n",
      "Epoch 74/150\n",
      "34/34 [==============================] - 26s 771ms/sample - loss: 30.5994 - _calculate_reconstruction_loss: 0.0190 - _calculate_kl_loss: 11.6120\n",
      "Epoch 75/150\n",
      "34/34 [==============================] - 27s 795ms/sample - loss: 29.1530 - _calculate_reconstruction_loss: 0.0236 - _calculate_kl_loss: 5.5922\n",
      "Epoch 76/150\n",
      "34/34 [==============================] - 27s 802ms/sample - loss: 30.8275 - _calculate_reconstruction_loss: 0.0190 - _calculate_kl_loss: 11.7896\n",
      "Epoch 77/150\n",
      "34/34 [==============================] - 27s 794ms/sample - loss: 32.6758 - _calculate_reconstruction_loss: 0.0271 - _calculate_kl_loss: 5.5279\n",
      "Epoch 78/150\n",
      "34/34 [==============================] - 27s 786ms/sample - loss: 45.4851 - _calculate_reconstruction_loss: 0.0199 - _calculate_kl_loss: 25.5707\n",
      "Epoch 79/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 32.8472 - _calculate_reconstruction_loss: 0.0261 - _calculate_kl_loss: 6.7760\n",
      "Epoch 80/150\n",
      "34/34 [==============================] - 27s 784ms/sample - loss: 28.7158 - _calculate_reconstruction_loss: 0.0207 - _calculate_kl_loss: 7.9972\n",
      "Epoch 81/150\n",
      "34/34 [==============================] - 26s 778ms/sample - loss: 28.1741 - _calculate_reconstruction_loss: 0.0207 - _calculate_kl_loss: 7.4820\n",
      "Epoch 82/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 38.3134 - _calculate_reconstruction_loss: 0.0202 - _calculate_kl_loss: 18.0733\n",
      "Epoch 83/150\n",
      "34/34 [==============================] - 26s 766ms/sample - loss: 34.9301 - _calculate_reconstruction_loss: 0.0208 - _calculate_kl_loss: 14.0819\n",
      "Epoch 84/150\n",
      "34/34 [==============================] - 27s 781ms/sample - loss: 45.1870 - _calculate_reconstruction_loss: 0.0202 - _calculate_kl_loss: 24.9543\n",
      "Epoch 85/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 36.1941 - _calculate_reconstruction_loss: 0.0200 - _calculate_kl_loss: 16.1630\n",
      "Epoch 86/150\n",
      "34/34 [==============================] - 27s 788ms/sample - loss: 51.4980 - _calculate_reconstruction_loss: 0.0196 - _calculate_kl_loss: 31.9346\n",
      "Epoch 87/150\n",
      "34/34 [==============================] - 27s 795ms/sample - loss: 47.0645 - _calculate_reconstruction_loss: 0.0200 - _calculate_kl_loss: 27.1109\n",
      "Epoch 88/150\n",
      "34/34 [==============================] - 27s 788ms/sample - loss: 41.7455 - _calculate_reconstruction_loss: 0.0239 - _calculate_kl_loss: 17.8109\n",
      "Epoch 89/150\n",
      "34/34 [==============================] - 27s 784ms/sample - loss: 35.1842 - _calculate_reconstruction_loss: 0.0194 - _calculate_kl_loss: 15.7662\n",
      "Epoch 90/150\n",
      "34/34 [==============================] - 26s 771ms/sample - loss: 35.7447 - _calculate_reconstruction_loss: 0.0215 - _calculate_kl_loss: 14.2004\n",
      "Epoch 91/150\n",
      "34/34 [==============================] - 27s 782ms/sample - loss: 31.9457 - _calculate_reconstruction_loss: 0.0199 - _calculate_kl_loss: 12.0161\n",
      "Epoch 92/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 31.2029 - _calculate_reconstruction_loss: 0.0196 - _calculate_kl_loss: 11.5929\n",
      "Epoch 93/150\n",
      "34/34 [==============================] - 26s 772ms/sample - loss: 29.4486 - _calculate_reconstruction_loss: 0.0193 - _calculate_kl_loss: 10.1130\n",
      "Epoch 94/150\n",
      "34/34 [==============================] - 26s 776ms/sample - loss: 26.8663 - _calculate_reconstruction_loss: 0.0199 - _calculate_kl_loss: 6.9462\n",
      "Epoch 95/150\n",
      "34/34 [==============================] - 26s 769ms/sample - loss: 28.6875 - _calculate_reconstruction_loss: 0.0223 - _calculate_kl_loss: 6.4309\n",
      "Epoch 96/150\n",
      "34/34 [==============================] - 26s 773ms/sample - loss: 25.7881 - _calculate_reconstruction_loss: 0.0184 - _calculate_kl_loss: 7.4280\n",
      "Epoch 97/150\n",
      "34/34 [==============================] - 26s 773ms/sample - loss: 26.6638 - _calculate_reconstruction_loss: 0.0209 - _calculate_kl_loss: 5.7602\n",
      "Epoch 98/150\n",
      "34/34 [==============================] - 27s 792ms/sample - loss: 24.8376 - _calculate_reconstruction_loss: 0.0189 - _calculate_kl_loss: 5.9462\n",
      "Epoch 99/150\n",
      "34/34 [==============================] - 27s 788ms/sample - loss: 25.4258 - _calculate_reconstruction_loss: 0.0207 - _calculate_kl_loss: 4.7602\n",
      "Epoch 100/150\n",
      "34/34 [==============================] - 27s 788ms/sample - loss: 23.8244 - _calculate_reconstruction_loss: 0.0190 - _calculate_kl_loss: 4.7778\n",
      "Epoch 101/150\n",
      "34/34 [==============================] - 26s 773ms/sample - loss: 22.9277 - _calculate_reconstruction_loss: 0.0185 - _calculate_kl_loss: 4.3817\n",
      "Epoch 102/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 24.8829 - _calculate_reconstruction_loss: 0.0202 - _calculate_kl_loss: 4.6678\n",
      "Epoch 103/150\n",
      "34/34 [==============================] - 27s 780ms/sample - loss: 24.7866 - _calculate_reconstruction_loss: 0.0188 - _calculate_kl_loss: 5.9666\n",
      "Epoch 104/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 24.5159 - _calculate_reconstruction_loss: 0.0193 - _calculate_kl_loss: 5.2300\n",
      "Epoch 105/150\n",
      "34/34 [==============================] - 26s 776ms/sample - loss: 24.1547 - _calculate_reconstruction_loss: 0.0185 - _calculate_kl_loss: 5.6310\n",
      "Epoch 106/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 23.8407 - _calculate_reconstruction_loss: 0.0189 - _calculate_kl_loss: 4.9711\n",
      "Epoch 107/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 23.6635 - _calculate_reconstruction_loss: 0.0188 - _calculate_kl_loss: 4.8637\n",
      "Epoch 108/150\n",
      "34/34 [==============================] - 26s 771ms/sample - loss: 23.6425 - _calculate_reconstruction_loss: 0.0186 - _calculate_kl_loss: 5.0588\n",
      "Epoch 109/150\n",
      "34/34 [==============================] - 27s 792ms/sample - loss: 23.2677 - _calculate_reconstruction_loss: 0.0184 - _calculate_kl_loss: 4.8499\n",
      "Epoch 110/150\n",
      "34/34 [==============================] - 27s 791ms/sample - loss: 23.1939 - _calculate_reconstruction_loss: 0.0173 - _calculate_kl_loss: 5.8663\n",
      "Epoch 111/150\n",
      "34/34 [==============================] - 27s 788ms/sample - loss: 23.6153 - _calculate_reconstruction_loss: 0.0183 - _calculate_kl_loss: 5.3172\n",
      "Epoch 112/150\n",
      "34/34 [==============================] - 27s 784ms/sample - loss: 23.3940 - _calculate_reconstruction_loss: 0.0181 - _calculate_kl_loss: 5.3050\n",
      "Epoch 113/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 28.4218 - _calculate_reconstruction_loss: 0.0180 - _calculate_kl_loss: 10.4048\n",
      "Epoch 114/150\n",
      "34/34 [==============================] - 26s 773ms/sample - loss: 26.8859 - _calculate_reconstruction_loss: 0.0203 - _calculate_kl_loss: 6.5518\n",
      "Epoch 115/150\n",
      "34/34 [==============================] - 26s 766ms/sample - loss: 243.4313 - _calculate_reconstruction_loss: 0.0205 - _calculate_kl_loss: 222.9030\n",
      "Epoch 116/150\n",
      "34/34 [==============================] - 26s 778ms/sample - loss: 156.7978 - _calculate_reconstruction_loss: 0.0228 - _calculate_kl_loss: 134.0072\n",
      "Epoch 117/150\n",
      "34/34 [==============================] - 26s 771ms/sample - loss: 127.7582 - _calculate_reconstruction_loss: 0.0363 - _calculate_kl_loss: 91.4320\n",
      "Epoch 118/150\n",
      "34/34 [==============================] - 26s 771ms/sample - loss: 85.8762 - _calculate_reconstruction_loss: 0.0196 - _calculate_kl_loss: 66.2836\n",
      "Epoch 119/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 82.6052 - _calculate_reconstruction_loss: 0.0259 - _calculate_kl_loss: 56.6772\n",
      "Epoch 120/150\n",
      "34/34 [==============================] - 26s 776ms/sample - loss: 68.5088 - _calculate_reconstruction_loss: 0.0197 - _calculate_kl_loss: 48.7631\n",
      "Epoch 121/150\n",
      "34/34 [==============================] - 27s 788ms/sample - loss: 61.7600 - _calculate_reconstruction_loss: 0.0210 - _calculate_kl_loss: 40.7883\n",
      "Epoch 122/150\n",
      "34/34 [==============================] - 27s 791ms/sample - loss: 49.7372 - _calculate_reconstruction_loss: 0.0197 - _calculate_kl_loss: 30.0773\n",
      "Epoch 123/150\n",
      "34/34 [==============================] - 26s 779ms/sample - loss: 48.7706 - _calculate_reconstruction_loss: 0.0193 - _calculate_kl_loss: 29.4581\n",
      "Epoch 124/150\n",
      "34/34 [==============================] - 26s 767ms/sample - loss: 38.9475 - _calculate_reconstruction_loss: 0.0199 - _calculate_kl_loss: 19.0939\n",
      "Epoch 125/150\n",
      "34/34 [==============================] - 26s 769ms/sample - loss: 37.5834 - _calculate_reconstruction_loss: 0.0187 - _calculate_kl_loss: 18.8354\n",
      "Epoch 126/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 33.0211 - _calculate_reconstruction_loss: 0.0177 - _calculate_kl_loss: 15.3406\n",
      "Epoch 127/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 31.8721 - _calculate_reconstruction_loss: 0.0170 - _calculate_kl_loss: 14.8832\n",
      "Epoch 128/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 30.0519 - _calculate_reconstruction_loss: 0.0174 - _calculate_kl_loss: 12.6790\n",
      "Epoch 129/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 28.9617 - _calculate_reconstruction_loss: 0.0185 - _calculate_kl_loss: 10.4765\n",
      "Epoch 130/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 27.7722 - _calculate_reconstruction_loss: 0.0168 - _calculate_kl_loss: 10.9713\n",
      "Epoch 131/150\n",
      "34/34 [==============================] - 26s 772ms/sample - loss: 27.1242 - _calculate_reconstruction_loss: 0.0185 - _calculate_kl_loss: 8.6227\n",
      "Epoch 132/150\n",
      "34/34 [==============================] - 27s 795ms/sample - loss: 26.1216 - _calculate_reconstruction_loss: 0.0181 - _calculate_kl_loss: 8.0146\n",
      "Epoch 133/150\n",
      "34/34 [==============================] - 27s 789ms/sample - loss: 25.4261 - _calculate_reconstruction_loss: 0.0176 - _calculate_kl_loss: 7.8258\n",
      "Epoch 134/150\n",
      "34/34 [==============================] - 27s 787ms/sample - loss: 25.5395 - _calculate_reconstruction_loss: 0.0182 - _calculate_kl_loss: 7.3224\n",
      "Epoch 135/150\n",
      "34/34 [==============================] - 26s 766ms/sample - loss: 24.5432 - _calculate_reconstruction_loss: 0.0176 - _calculate_kl_loss: 6.9466\n",
      "Epoch 136/150\n",
      "34/34 [==============================] - 26s 767ms/sample - loss: 25.2329 - _calculate_reconstruction_loss: 0.0183 - _calculate_kl_loss: 6.9715\n",
      "Epoch 137/150\n",
      "34/34 [==============================] - 26s 777ms/sample - loss: 24.4778 - _calculate_reconstruction_loss: 0.0175 - _calculate_kl_loss: 6.9738\n",
      "Epoch 138/150\n",
      "34/34 [==============================] - 26s 764ms/sample - loss: 22.7247 - _calculate_reconstruction_loss: 0.0158 - _calculate_kl_loss: 6.9368\n",
      "Epoch 139/150\n",
      "34/34 [==============================] - 26s 774ms/sample - loss: 22.8338 - _calculate_reconstruction_loss: 0.0167 - _calculate_kl_loss: 6.0875\n",
      "Epoch 140/150\n",
      "34/34 [==============================] - 26s 769ms/sample - loss: 22.7664 - _calculate_reconstruction_loss: 0.0172 - _calculate_kl_loss: 5.5839\n",
      "Epoch 141/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 21.9484 - _calculate_reconstruction_loss: 0.0158 - _calculate_kl_loss: 6.1856\n",
      "Epoch 142/150\n",
      "34/34 [==============================] - 26s 763ms/sample - loss: 22.3063 - _calculate_reconstruction_loss: 0.0164 - _calculate_kl_loss: 5.9453\n",
      "Epoch 143/150\n",
      "34/34 [==============================] - 27s 782ms/sample - loss: 22.3012 - _calculate_reconstruction_loss: 0.0171 - _calculate_kl_loss: 5.1691\n",
      "Epoch 144/150\n",
      "34/34 [==============================] - 27s 790ms/sample - loss: 26.0589 - _calculate_reconstruction_loss: 0.0172 - _calculate_kl_loss: 8.8674\n",
      "Epoch 145/150\n",
      "34/34 [==============================] - 27s 794ms/sample - loss: 22.7359 - _calculate_reconstruction_loss: 0.0163 - _calculate_kl_loss: 6.4700\n",
      "Epoch 146/150\n",
      "34/34 [==============================] - 27s 789ms/sample - loss: 23.3870 - _calculate_reconstruction_loss: 0.0168 - _calculate_kl_loss: 6.5525\n",
      "Epoch 147/150\n",
      "34/34 [==============================] - 26s 769ms/sample - loss: 22.1749 - _calculate_reconstruction_loss: 0.0158 - _calculate_kl_loss: 6.3400\n",
      "Epoch 148/150\n",
      "34/34 [==============================] - 26s 775ms/sample - loss: 22.9411 - _calculate_reconstruction_loss: 0.0154 - _calculate_kl_loss: 7.5869\n",
      "Epoch 149/150\n",
      "34/34 [==============================] - 26s 770ms/sample - loss: 21.0695 - _calculate_reconstruction_loss: 0.0153 - _calculate_kl_loss: 5.7637\n",
      "Epoch 150/150\n",
      "34/34 [==============================] - 26s 771ms/sample - loss: 21.1827 - _calculate_reconstruction_loss: 0.0155 - _calculate_kl_loss: 5.7003\n"
     ]
    }
   ],
   "source": [
    "x_train = load_fsdd(SPECTROGRAMS_PATH)\n",
    "autoencoder = train(x_train, LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "autoencoder.save(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundGenerator:\n",
    "    \"\"\"SoundGenerator is responsible for generating audios from\n",
    "    spectrograms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vae, hop_length):\n",
    "        self.vae = vae\n",
    "        self.hop_length = hop_length\n",
    "        self._min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "\n",
    "    def generate(self, spectrograms, min_max_values):\n",
    "        generated_spectrograms, latent_representations = \\\n",
    "            self.vae.reconstruct(spectrograms)\n",
    "        signals = self.convert_spectrograms_to_audio(generated_spectrograms, min_max_values)\n",
    "        return signals, latent_representations\n",
    "\n",
    "    def convert_spectrograms_to_audio(self, spectrograms, min_max_values):\n",
    "        signals = []\n",
    "        for spectrogram, min_max_value in zip(spectrograms, min_max_values):\n",
    "            # reshape the log spectrogram\n",
    "            log_spectrogram = spectrogram[:, :, 0]\n",
    "            # apply denormalisation\n",
    "            denorm_log_spec = self._min_max_normaliser.denormalise(\n",
    "                log_spectrogram, min_max_value[\"min\"], min_max_value[\"max\"])\n",
    "            # log spectrogram -> spectrogram\n",
    "            spec = librosa.db_to_amplitude(denorm_log_spec)\n",
    "            # apply Griffin-Lim\n",
    "            signal = librosa.istft(spec, hop_length=self.hop_length)\n",
    "            # append signal to \"signals\"\n",
    "            signals.append(signal)\n",
    "        return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "HOP_LENGTH = 256\n",
    "SAVE_DIR_ORIGINAL = \"samples/original/\"\n",
    "SAVE_DIR_GENERATED = \"samples/generated/\"\n",
    "MIN_MAX_VALUES_PATH = \"maestro_dataset/minmax/min_max_values.pkl\"\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    file_paths = []\n",
    "    print(spectrograms_path)\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 64, 1)\n",
    "    return x_train, file_paths\n",
    "\n",
    "\n",
    "def select_spectrograms(spectrograms,\n",
    "                        file_paths,\n",
    "                        min_max_values,\n",
    "                        num_spectrograms=2):\n",
    "    sampled_indexes = np.random.choice(range(len(spectrograms)), num_spectrograms)\n",
    "    sampled_spectrogrmas = spectrograms[sampled_indexes]\n",
    "    file_paths = [file_paths[index] for index in sampled_indexes]\n",
    "    print(file_paths)\n",
    "    print(min_max_values)\n",
    "    sampled_min_max_values = [min_max_values[file_path] for file_path in\n",
    "                           file_paths]\n",
    "    print(file_paths)\n",
    "    print(sampled_min_max_values)\n",
    "    return sampled_spectrogrmas, sampled_min_max_values\n",
    "\n",
    "\n",
    "def save_signals(signals, save_dir, sample_rate=22050):\n",
    "    for i, signal in enumerate(signals):\n",
    "        save_path = os.path.join(save_dir, str(i) + \".wav\")\n",
    "        sf.write(save_path, signal, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 388, 1)\n",
      "{'maestro_dataset/spectograms/sound_file_21.wav.npy': {'min': -71.81659, 'max': 8.18341}, 'maestro_dataset/spectograms/sound_file_14.wav.npy': {'min': -74.29232, 'max': 5.7076826}, 'maestro_dataset/spectograms/sound_file_27.wav.npy': {'min': -77.000854, 'max': 2.999144}, 'maestro_dataset/spectograms/sound_file_15.wav.npy': {'min': -72.51567, 'max': 7.484332}, 'maestro_dataset/spectograms/sound_file_17.wav.npy': {'min': -83.64062, 'max': -3.6406162}, 'maestro_dataset/spectograms/sound_file_8.wav.npy': {'min': -74.28023, 'max': 5.719772}, 'maestro_dataset/spectograms/sound_file_6.wav.npy': {'min': -71.25693, 'max': 8.7430725}, 'maestro_dataset/spectograms/sound_file_19.wav.npy': {'min': -70.32506, 'max': 9.674939}, 'maestro_dataset/spectograms/sound_file_20.wav.npy': {'min': -73.830765, 'max': 6.1692386}, 'maestro_dataset/spectograms/sound_file_13.wav.npy': {'min': -81.36227, 'max': -1.3622642}, 'maestro_dataset/spectograms/sound_file_23.wav.npy': {'min': -80.738686, 'max': -0.7386857}, 'maestro_dataset/spectograms/sound_file_3.wav.npy': {'min': -67.72164, 'max': 12.2783575}, 'maestro_dataset/spectograms/sound_file_33.wav.npy': {'min': -67.86448, 'max': 12.13552}, 'maestro_dataset/spectograms/sound_file_12.wav.npy': {'min': -79.56744, 'max': 0.43256247}, 'maestro_dataset/spectograms/sound_file_5.wav.npy': {'min': -70.6294, 'max': 9.3706}, 'maestro_dataset/spectograms/sound_file_0.wav.npy': {'min': -81.85995, 'max': -1.8599504}, 'maestro_dataset/spectograms/sound_file_10.wav.npy': {'min': -84.83482, 'max': -4.834823}, 'maestro_dataset/spectograms/sound_file_31.wav.npy': {'min': -75.130516, 'max': 4.869485}, 'maestro_dataset/spectograms/sound_file_16.wav.npy': {'min': -75.47286, 'max': 4.5271373}, 'maestro_dataset/spectograms/sound_file_9.wav.npy': {'min': -76.12672, 'max': 3.8732834}, 'maestro_dataset/spectograms/sound_file_18.wav.npy': {'min': -81.470764, 'max': -1.4707613}, 'maestro_dataset/spectograms/sound_file_22.wav.npy': {'min': -68.96388, 'max': 11.036115}, 'maestro_dataset/spectograms/sound_file_11.wav.npy': {'min': -71.73612, 'max': 8.263875}, 'maestro_dataset/spectograms/sound_file_1.wav.npy': {'min': -71.89324, 'max': 8.106759}, 'maestro_dataset/spectograms/sound_file_2.wav.npy': {'min': -73.40772, 'max': 6.592281}, 'maestro_dataset/spectograms/sound_file_24.wav.npy': {'min': -71.61896, 'max': 8.381046}, 'maestro_dataset/spectograms/sound_file_28.wav.npy': {'min': -76.094406, 'max': 3.9055963}, 'maestro_dataset/spectograms/sound_file_25.wav.npy': {'min': -82.557945, 'max': -2.5579462}, 'maestro_dataset/spectograms/sound_file_7.wav.npy': {'min': -80.583916, 'max': -0.5839122}, 'maestro_dataset/spectograms/sound_file_4.wav.npy': {'min': -73.30006, 'max': 6.6999426}, 'maestro_dataset/spectograms/sound_file_30.wav.npy': {'min': -82.74453, 'max': -2.7445269}, 'maestro_dataset/spectograms/sound_file_26.wav.npy': {'min': -71.41737, 'max': 8.582626}, 'maestro_dataset/spectograms/sound_file_29.wav.npy': {'min': -74.467896, 'max': 5.5321064}, 'maestro_dataset/spectograms/sound_file_32.wav.npy': {'min': -79.46314, 'max': 0.5368549}}\n",
      "maestro_dataset/spectograms\n",
      "['maestro_dataset/spectograms/sound_file_29.wav.npy', 'maestro_dataset/spectograms/sound_file_28.wav.npy', 'maestro_dataset/spectograms/sound_file_24.wav.npy', 'maestro_dataset/spectograms/sound_file_24.wav.npy', 'maestro_dataset/spectograms/sound_file_24.wav.npy']\n",
      "{'maestro_dataset/spectograms/sound_file_21.wav.npy': {'min': -71.81659, 'max': 8.18341}, 'maestro_dataset/spectograms/sound_file_14.wav.npy': {'min': -74.29232, 'max': 5.7076826}, 'maestro_dataset/spectograms/sound_file_27.wav.npy': {'min': -77.000854, 'max': 2.999144}, 'maestro_dataset/spectograms/sound_file_15.wav.npy': {'min': -72.51567, 'max': 7.484332}, 'maestro_dataset/spectograms/sound_file_17.wav.npy': {'min': -83.64062, 'max': -3.6406162}, 'maestro_dataset/spectograms/sound_file_8.wav.npy': {'min': -74.28023, 'max': 5.719772}, 'maestro_dataset/spectograms/sound_file_6.wav.npy': {'min': -71.25693, 'max': 8.7430725}, 'maestro_dataset/spectograms/sound_file_19.wav.npy': {'min': -70.32506, 'max': 9.674939}, 'maestro_dataset/spectograms/sound_file_20.wav.npy': {'min': -73.830765, 'max': 6.1692386}, 'maestro_dataset/spectograms/sound_file_13.wav.npy': {'min': -81.36227, 'max': -1.3622642}, 'maestro_dataset/spectograms/sound_file_23.wav.npy': {'min': -80.738686, 'max': -0.7386857}, 'maestro_dataset/spectograms/sound_file_3.wav.npy': {'min': -67.72164, 'max': 12.2783575}, 'maestro_dataset/spectograms/sound_file_33.wav.npy': {'min': -67.86448, 'max': 12.13552}, 'maestro_dataset/spectograms/sound_file_12.wav.npy': {'min': -79.56744, 'max': 0.43256247}, 'maestro_dataset/spectograms/sound_file_5.wav.npy': {'min': -70.6294, 'max': 9.3706}, 'maestro_dataset/spectograms/sound_file_0.wav.npy': {'min': -81.85995, 'max': -1.8599504}, 'maestro_dataset/spectograms/sound_file_10.wav.npy': {'min': -84.83482, 'max': -4.834823}, 'maestro_dataset/spectograms/sound_file_31.wav.npy': {'min': -75.130516, 'max': 4.869485}, 'maestro_dataset/spectograms/sound_file_16.wav.npy': {'min': -75.47286, 'max': 4.5271373}, 'maestro_dataset/spectograms/sound_file_9.wav.npy': {'min': -76.12672, 'max': 3.8732834}, 'maestro_dataset/spectograms/sound_file_18.wav.npy': {'min': -81.470764, 'max': -1.4707613}, 'maestro_dataset/spectograms/sound_file_22.wav.npy': {'min': -68.96388, 'max': 11.036115}, 'maestro_dataset/spectograms/sound_file_11.wav.npy': {'min': -71.73612, 'max': 8.263875}, 'maestro_dataset/spectograms/sound_file_1.wav.npy': {'min': -71.89324, 'max': 8.106759}, 'maestro_dataset/spectograms/sound_file_2.wav.npy': {'min': -73.40772, 'max': 6.592281}, 'maestro_dataset/spectograms/sound_file_24.wav.npy': {'min': -71.61896, 'max': 8.381046}, 'maestro_dataset/spectograms/sound_file_28.wav.npy': {'min': -76.094406, 'max': 3.9055963}, 'maestro_dataset/spectograms/sound_file_25.wav.npy': {'min': -82.557945, 'max': -2.5579462}, 'maestro_dataset/spectograms/sound_file_7.wav.npy': {'min': -80.583916, 'max': -0.5839122}, 'maestro_dataset/spectograms/sound_file_4.wav.npy': {'min': -73.30006, 'max': 6.6999426}, 'maestro_dataset/spectograms/sound_file_30.wav.npy': {'min': -82.74453, 'max': -2.7445269}, 'maestro_dataset/spectograms/sound_file_26.wav.npy': {'min': -71.41737, 'max': 8.582626}, 'maestro_dataset/spectograms/sound_file_29.wav.npy': {'min': -74.467896, 'max': 5.5321064}, 'maestro_dataset/spectograms/sound_file_32.wav.npy': {'min': -79.46314, 'max': 0.5368549}}\n",
      "['maestro_dataset/spectograms/sound_file_29.wav.npy', 'maestro_dataset/spectograms/sound_file_28.wav.npy', 'maestro_dataset/spectograms/sound_file_24.wav.npy', 'maestro_dataset/spectograms/sound_file_24.wav.npy', 'maestro_dataset/spectograms/sound_file_24.wav.npy']\n",
      "[{'min': -74.467896, 'max': 5.5321064}, {'min': -76.094406, 'max': 3.9055963}, {'min': -71.61896, 'max': 8.381046}, {'min': -71.61896, 'max': 8.381046}, {'min': -71.61896, 'max': 8.381046}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# initialise sound generator\n",
    "vae = VAE.load(\"model\")\n",
    "sound_generator = SoundGenerator(vae, HOP_LENGTH)\n",
    "\n",
    "# load spectrograms + min max values\n",
    "with open(MIN_MAX_VALUES_PATH, \"rb\") as f:\n",
    "    min_max_values = pickle.load(f)\n",
    "    print(min_max_values)\n",
    "    \n",
    "specs, file_paths = load_fsdd(SPECTROGRAMS_PATH)\n",
    "\n",
    "# sample spectrograms + min max values\n",
    "sampled_specs, sampled_min_max_values = select_spectrograms(specs,\n",
    "                                                            file_paths,\n",
    "                                                            min_max_values,\n",
    "                                                            5)\n",
    "\n",
    "\n",
    "# generate audio for sampled spectrograms\n",
    "signals, _ = sound_generator.generate(sampled_specs,\n",
    "                                      sampled_min_max_values)\n",
    "\n",
    "# convert spectrogram samples to audio\n",
    "original_signals = sound_generator.convert_spectrograms_to_audio(\n",
    "    sampled_specs, sampled_min_max_values)\n",
    "\n",
    "# save audio signals\n",
    "save_signals(signals, SAVE_DIR_GENERATED)\n",
    "save_signals(original_signals, SAVE_DIR_ORIGINAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
